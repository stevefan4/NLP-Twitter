{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "!pip3 install numpy --upgrade\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import nltk\n",
    "import re\n",
    "import contractions\n",
    "import gensim\n",
    "import keras\n",
    "#!pip install GetOldTweets3\n",
    "import GetOldTweets3 as got\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string, strip_tags, strip_punctuation, stem_text, preprocess_documents, strip_multiple_whitespaces, strip_non_alphanum, strip_short\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from textblob import TextBlob\n",
    "#!pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Flatten, BatchNormalization, TimeDistributed, GlobalMaxPooling1D, MaxPooling1D, MaxPooling2D, Conv1D, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "pd.options.display.max_colwidth = 600\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d79aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/steve/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "additional_words = ('joebiden', 'biden', 'donaldtrump', 'trump', 'barackobama', 'obama')\n",
    "for ele in additional_words:\n",
    "    words.add(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e85f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, strip_punctuation, strip_non_alphanum, stem_text,\n",
    "                  remove_stopwords, strip_short]\n",
    "\n",
    "#stop = stopwords.words('english')\n",
    "#stop.extend(['amp','aaa'])\n",
    "\n",
    "def prep(sentence): \n",
    "    sentence = contractions.fix(sentence)\n",
    "    split_sentence = sentence.split()\n",
    "    return preprocess_string(sentence, CUSTOM_FILTERS)\n",
    "\n",
    "def prep_withspell(sentence):\n",
    "    holder = \" \"\n",
    "    sentence = contractions.fix(sentence)\n",
    "    preprocessed = preprocess_string(sentence, CUSTOM_FILTERS)\n",
    "    spell_correct = TextBlob(holder.join(preprocessed))\n",
    "    corrected_sentence = spell_correct.correct()\n",
    "    return corrected_sentence.split()    \n",
    "\n",
    "def prepare(sentence): \n",
    "    processed_feature = re.sub(r'\\W', ' ', str(sentence))\n",
    "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
    "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "    processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
    "    processed_feature = processed_feature.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sentence = processed_feature.split()\n",
    "    removed_stopwords = [w for w in sentence if not w.lower() in stop_words]    \n",
    "    return ' '.join(removed_stopwords)\n",
    "\n",
    "def cont_to_multiclass(cont):\n",
    "    if cont > 0.66:\n",
    "        return 'highly positive'\n",
    "    elif cont > 0.33:\n",
    "        return 'positive'\n",
    "    elif cont > 0:\n",
    "        return 'partly positive'\n",
    "    elif cont > -0.33:\n",
    "        return 'partly negative'\n",
    "    elif cont > -0.66:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'highly negative'\n",
    "\n",
    "def cont_to_binary(cont):\n",
    "    if cont > 0:\n",
    "        #return 'positive'\n",
    "        return 1\n",
    "    else:\n",
    "        #return 'negative'\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0838a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_frequency(data, wi, wj=None):\n",
    "    if wj is None:\n",
    "        D_wi = 0\n",
    "        for l in range(len(data)):\n",
    "            doc = data[l]\n",
    "            if wi in doc:\n",
    "                D_wi += 1\n",
    "        return D_wi\n",
    "    D_wj = 0\n",
    "    D_wi_wj = 0\n",
    "    for l in range(len(data)):\n",
    "        doc = data[l]\n",
    "        if wj in doc:\n",
    "            D_wj += 1\n",
    "            if wi in doc:\n",
    "                D_wi_wj += 1\n",
    "    return D_wj, D_wi_wj\n",
    "\n",
    "def get_topic_coherence(beta, data, vocab, seed):\n",
    "    D = len(data)\n",
    "    TC = []\n",
    "    num_topics = len(beta.components_)\n",
    "    selected = -1\n",
    "    selected = []\n",
    "    for k, topic in enumerate(beta.components_):\n",
    "        print('k: {}/{}'.format(k, num_topics))\n",
    "        top_10 = topic.argsort()[:-20 - 1:-1]\n",
    "        top_words = [vocab[i] for i in top_10]\n",
    "        print(top_words)\n",
    "        TC_k = 0\n",
    "        counter = 0\n",
    "        for i, word in enumerate(top_words):\n",
    "            D_wi = get_document_frequency(data, word)\n",
    "            j = i + 1\n",
    "            tmp = 0\n",
    "            while j < len(top_10) and j > i:\n",
    "                D_wj, D_wi_wj = get_document_frequency(data, word, top_words[j])\n",
    "                if D_wi_wj == 0:\n",
    "                    f_wi_wj = -1\n",
    "                else:\n",
    "                    f_wi_wj = -1 + ( np.log(D_wi) + np.log(D_wj)  - 2.0 * np.log(D) ) / ( np.log(D_wi_wj) - np.log(D) )\n",
    "                tmp += f_wi_wj\n",
    "                j += 1\n",
    "                counter += 1\n",
    "            TC_k += tmp \n",
    "        TC.append(TC_k)\n",
    "    print('num topics: ', len(TC))\n",
    "    print('Topic Coherence is: {}'.format(TC))\n",
    "    return TC, selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8b19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scores(sentence):\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    return sentiment_dict['compound']\n",
    "    #print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
    "    #print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\")\n",
    "    #print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\")\n",
    "    #print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\")\n",
    "    #print(\"Sentence Overall Rated As\", end = \" \")\n",
    " \n",
    "    #if sentiment_dict['compound'] >= 0.05 :\n",
    "        #return \"Positive\"\n",
    "    #elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        #return \"Negative\"\n",
    "    #else :\n",
    "        #return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d8b2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(model, tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model.wv[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:  # handling the case where the token is not in vocabulary\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8f091bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return np.array(regressors)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf7c323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-174ca8b73105>:10: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  leftwing_df = pd.read_csv('leftwing.csv', error_bad_lines=False, header=None, index_col=False, sep=\"<|>\", lineterminator='\\n')\n",
      "<ipython-input-8-174ca8b73105>:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  rightwing_df = pd.read_csv('rightwing.csv', error_bad_lines=False, header=None, index_col=False, sep=\"<|>\", lineterminator='\\n')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/steve/GetOldTweets3-0.0.10')\n",
    "\n",
    "key_words = ['leftwing', 'rightwing', 'liberal', 'leftist', 'conservative', 'politics', 'political', 'antifa', 'gop',\n",
    "            'democrat', 'trump', 'maga', 'republican', 'politicians', 'vote', 'government', 'breakingnews', 'worldnews', \n",
    "            'news', 'fakenews', 'obama', 'tcot', 'p2']\n",
    "\n",
    "key_word_test = ['leftwing', 'rightwing']\n",
    "\n",
    "leftwing_df = pd.read_csv('leftwing.csv', error_bad_lines=False, header=None, index_col=False, sep=\"<|>\", lineterminator='\\n')\n",
    "rightwing_df = pd.read_csv('rightwing.csv', error_bad_lines=False, header=None, index_col=False, sep=\"<|>\", lineterminator='\\n')\n",
    "#liberal_df = pd.read_csv('liberal.csv', error_bad_lines=False, header=None, index_col=False, sep= '<|>'', lineterminator='\\n')\n",
    "#leftist_df = pd.read_csv('leftist.csv', error_bad_lines=False, header=None, index_col=False, sep='<|>', lineterminator='\\n')\n",
    "#conservative_df = pd.read_csv('conservative.csv', error_bad_lines=False, header=None, index_col=False, sep='<|>', lineterminator='\\n')\n",
    "#politics_df = pd.read_csv('politics.csv', error_bad_lines=False, header=None, index_col=False, sep='<|>', lineterminator='\\n')\n",
    "#political_df = pd.read_csv('political.csv', error_bad_lines=False, header=None, index_col=False, sep='<|>', lineterminator='\\n')\n",
    "#gop_df = pd.read_csv('gop.csv', error_bad_lines=False, header=None, index_col=False, sep='<|>', lineterminator='\\n')\n",
    "#democrat_df = pd.read_csv('democrat.csv', error_bad_lines=False, header=None, index_col=False, sep='<|>', lineterminator='\\n')\n",
    "#trump_df = pd.read_csv('trump.csv', error_bad_lines=False, header=None, index_col=False, sep='<|>', lineterminator='\\n')\n",
    "#republican_df = pd.read_csv('republican.csv', error_bad_lines=False, header=None, index_col=False, sep='<|>', lineterminator='\\n')\n",
    "#politicians_df = pd.read_csv('politicians.csv', error_bad_lines=False, header=None, index_col=False, sep='<|>', lineterminator='\\n')\n",
    "#fakenews = pd.read_csv('obama.csv', error_bad_lines=False, header=None, index_col=False, sep='<|>', lineterminator='\\n')\n",
    "#tcot = pd.read_csv('tcot.csv', error_bad_lines=False, header=None, index_col=False, sep='<|>', lineterminator='\\n')\n",
    "#p2 = pd.read_csv('p2.csv', error_bad_lines=False, header=None, index_col=False, sep='<|>', lineterminator='\\n')\n",
    "\n",
    "#frames = [leftwing_df, rightwing_df, liberal_df, leftist_df, conservative_df, politics_df, political_df, antifa_df, gop_df, democrat_df, trump_df, republican_df, politicians_df, vote_df, government_df, breakingnews_df, worldnews, news, fakenews, obama, tcot, p2]\n",
    "#result = pd.concat(frames, keys=key_words)\n",
    "\n",
    "frames_test = [leftwing_df, rightwing_df]\n",
    "result_test = pd.concat(frames_test, keys=key_word_test)\n",
    "result_test = result_test.drop_duplicates()\n",
    "holder = result_test[result_test[0].apply(lambda row: len(row.split()) < 4)]\n",
    "result_test = pd.concat((result_test, holder))\n",
    "result_test = result_test.drop_duplicates(keep=False)\n",
    "result_test[3] = result_test[2].apply(lambda row: str(row).split()[:6])\n",
    "result_test[3] = result_test[3].apply(lambda row: ' '.join([str(elem) for elem in row]))\n",
    "result_test = result_test.drop_duplicates(subset=[1, 3], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b38931",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test[0] = result_test.apply(lambda row: row[0].split()[1], axis=1)                                                \n",
    "result_test[2] = result_test.apply(lambda row: re.sub(r'http\\S+', '', str(row[2])), axis=1)\n",
    "result_test[2] = result_test.apply(lambda row: ''.join([c for c in row[2] if not c.isdigit()]), axis=1)\n",
    "result_test[3] = result_test.apply(lambda row : \" \".join(w for w in nltk.wordpunct_tokenize(row[2]) if w.lower() in words or not w.isalpha()), axis = 1)\n",
    "result_test[4] = result_test.apply(lambda row : prep(row[3]), axis = 1)\n",
    "result_test = result_test[result_test[4].map(len) >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c3babe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_test = [\" \".join(x) for x in result_test[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1738967a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109948, 74437)\n",
      "(109948, 1234871)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.90, min_df=3, stop_words='english', ngram_range=(1,3))\n",
    "dtm = tfidf.fit_transform(processed_data_test)\n",
    "\n",
    "tf_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3))\n",
    "tf_fit = tf_vectorizer.fit_transform(processed_data_test)\n",
    "print(dtm.shape)\n",
    "print(tf_fit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa5081d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steve/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    }
   ],
   "source": [
    "nmf_model = NMF(n_components=50, random_state=42, beta_loss='kullback-leibler', solver='mu', \n",
    "                max_iter=1000, alpha=2, l1_ratio=0.5)\n",
    "nmf_topics = nmf_model.fit_transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03b39d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=50, random_state=42, beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=2, l1_ratio=0.5).fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eae3863",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_test_df = pd.DataFrame(nmf.components_, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08a8a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_df = pd.DataFrame(nmf_model.components_, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aa7b15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 10 WORDS FOR TOPIC #0 GIVEN BY NMF:\n",
      "['leftist femin', 'polit donaldtrump', 'liber leftist', 'polit', 'femin', 'donaldtrump', 'trump polit', 'leftist', 'liber', 'world']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #1 GIVEN BY NMF:\n",
      "['joe biden', 'joe', 'readi polit democrat', 'trump', 'readi polit', 'readi', 'biden', 'polit', 'polit democrat', 'democrat']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #2 GIVEN BY NMF:\n",
      "['stupid', 'thought', 'onc', 'problem', 'sad', 'wonder', 'point', 'understand', 'everyon', 'turn']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #3 GIVEN BY NMF:\n",
      "['republican liber leftist', 'conserv republican liber', 'republican liber', 'polit conserv republican', 'trump polit conserv', 'polit conserv', 'trump', 'conserv republican', 'conserv', 'republican']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #4 GIVEN BY NMF:\n",
      "['presid joe biden', 'presid joe', 'presid biden', 'joe biden', 'joe', 'presid', 'polit', 'add polit', 'add', 'biden']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #5 GIVEN BY NMF:\n",
      "['upcom commun chat', 'upcom commun', 'polit upcom', 'chat polit', 'share polit', 'click', 'chat', 'upcom', 'share', 'commun']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #6 GIVEN BY NMF:\n",
      "['right wing polit', 'right polit', 'wing media', 'alt right', 'right wing media', 'extrem right', 'alt', 'right wing', 'wing', 'right']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #7 GIVEN BY NMF:\n",
      "['resist', 'conserv', 'liber polit', 'ralli', 'conserv liber', 'social', 'polit', 'liber', 'canada', 'trump']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #8 GIVEN BY NMF:\n",
      "['believ', 'thei onli', 'tell', 'thei believ', 'thei try', 'thei sai', 'sai thei', 'themselv', 'thei thei', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #9 GIVEN BY NMF:\n",
      "['thi thi', 'thread', 'thi year', 'articl', 'thi gui', 'happen', 'gui', 'thi week', 'week', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #10 GIVEN BY NMF:\n",
      "['yorker', 'local', 'year', 'studi', 'break', 'citi', 'report', 'fake', 'old', 'new']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #11 GIVEN BY NMF:\n",
      "['fight', 'plan', 'crisi', 'hous', 'rep', 'econom', 'tax', 'senat', 'congress', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #12 GIVEN BY NMF:\n",
      "['rest', 'dear', 'becom', 'ignor', 'feel', 'speak', 'poor', 'human', 'self', 'better']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #13 GIVEN BY NMF:\n",
      "['watch', 'biden readi polit', 'biden readi', 'white hous watch', 'hous watch', 'trump', 'press', 'white hous', 'hous', 'white']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #14 GIVEN BY NMF:\n",
      "['coverag', 'press', 'journal', 'journalist', 'social', 'cover', 'narr', 'stori', 'social media', 'media']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #15 GIVEN BY NMF:\n",
      "['presidenti debat', 'thei like', 'look', 'look like', 'debat polit democrat', 'like thei', 'debat polit', 'like thi', 'debat', 'like']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #16 GIVEN BY NMF:\n",
      "['impeach', 'administr', 'border', 'china', 'presid trump', 'senat', 'polit', 'trump', 'add polit', 'add']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #17 GIVEN BY NMF:\n",
      "['bird', 'right left', 'polit', 'socialist', 'lean', 'far left', 'left right', 'wing', 'left wing', 'left']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #18 GIVEN BY NMF:\n",
      "['million', 'white peopl', 'black peopl', 'mani', 'mani peopl', 'peopl thei', 'enemi', 'kill', 'peopl like', 'peopl']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #19 GIVEN BY NMF:\n",
      "['polit vote', 'ballot', 'govern polit', 'voter', 'polit', 'hypocrit', 'polit polit', 'candid', 'major', 'vote']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #20 GIVEN BY NMF:\n",
      "['warren', 'power', 'trump', 'link', 'promot', 'view', 'correct', 'awai', 'sander', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #21 GIVEN BY NMF:\n",
      "['new york', 'york', 'new polit', 'biden polit', 'polit', 'poll', 'fox new', 'post', 'fox', 'new']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #22 GIVEN BY NMF:\n",
      "['discrimin', 'hate violenc', 'rhetor', 'divis', 'bulli', 'bigotri', 'extrem', 'fear', 'violenc', 'hate']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #23 GIVEN BY NMF:\n",
      "['coalit', 'tea parti', 'labour', 'tea', 'awai', 'leader', 'democrat parti', 'republican parti', 'power', 'parti']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #24 GIVEN BY NMF:\n",
      "['parti', 'remain', 'join', 'meet', 'futur', 'german', 'russia', 'immigr', 'leader', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #25 GIVEN BY NMF:\n",
      "['danger', 'violent', 'terror', 'threat', 'far right', 'radic', 'rise', 'polic', 'extrem', 'far']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #26 GIVEN BY NMF:\n",
      "['street', 'union', 'daili', 'corpor', 'let', 'protest', 'immigr', 'pro', 'war', 'anti']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #27 GIVEN BY NMF:\n",
      "['strategi', 'influenc', 'written', 'alec', 'think thei', 'think tank', 'tank', 'member', 'group', 'think']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #28 GIVEN BY NMF:\n",
      "['bai time', 'ago', 'bai', 'morn', 'wast', 'thi time', 'east', 'long', 'everi', 'time']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #29 GIVEN BY NMF:\n",
      "['trump elect', 'colleg', 'elect polit', 'polit', 'presidenti', 'fraud', 'gener', 'night', 'lost', 'elect']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #30 GIVEN BY NMF:\n",
      "['alreadi', 'joebiden', 'agenda', 'win', 'doe', 'listen', 'befor', 'try', 'won', 'talk']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #31 GIVEN BY NMF:\n",
      "['barackobama', 'insan', 'progress', 'radio', 'funni', 'obama', 'crazi', 'blame', 'hypocrisi', 'realli']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #32 GIVEN BY NMF:\n",
      "['stand', 'need know', 'need stop', 'step', 'thei need', 'better', 'realli', 'help', 'start', 'need']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #33 GIVEN BY NMF:\n",
      "['small', 'current', 'possibl', 'minist', 'opposit', 'coup', 'brazil', 'corrupt', 'govern', 'onli']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #34 GIVEN BY NMF:\n",
      "['alreadi', 'doe', 'trump support', 'fascism', 'know thei', 'thei know', 'stand', 'becaus', 'know', 'support']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #35 GIVEN BY NMF:\n",
      "['outrag', 'trump campaign', 'rais', 'trump', 'dure', 'rememb', 'conspiraci', 'black', 'campaign', 'obama']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #36 GIVEN BY NMF:\n",
      "['cultur', 'religion', 'patriot', 'nation', 'base', 'religi', 'democraci', 'freedom', 'fascist', 'fascism']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #37 GIVEN BY NMF:\n",
      "['conserv trump', 'republican conserv', 'reason', 'trump republican', 'freedom', 'republican', 'libertarian', 'becaus thei', 'conserv', 'becaus']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #38 GIVEN BY NMF:\n",
      "['fact', 'check', 'anyth', 'woman', 'noth', 'health', 'anyon', 'follow', 'care', 'man']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #39 GIVEN BY NMF:\n",
      "['cult', 'someth', 'big', 'hope', 'covid', 'labour', 'pandem', 'sai', 'got', 'veri']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #40 GIVEN BY NMF:\n",
      "['sinc', 'domest', 'wait', 'respons', 'murder', 'terrorist', 'extremist', 'attack', 'terror', 'sai']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #41 GIVEN BY NMF:\n",
      "['latest', 'tax', 'fund', 'look', 'extrem', 'public', 'rich', 'tori', 'conspiraci', 'wai']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #42 GIVEN BY NMF:\n",
      "['rule', 'justic', 'hear', 'law', 'control', 'thei want', 'thi countri', 'nation', 'countri', 'want']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #43 GIVEN BY NMF:\n",
      "['leav', 'nut', 'bad', 'run', 'job', 'great', 'let', 'look', 'anoth', 'good']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #44 GIVEN BY NMF:\n",
      "['fascist', 'tell', 'bigot', 'ignor', 'race', 'danger', 'covid', 'racism', 'stop', 'racist']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #45 GIVEN BY NMF:\n",
      "['monei', 'god', 'video', 'said', 'climat', 'chang', 'believ', 'state', 'come', 'propaganda']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #46 GIVEN BY NMF:\n",
      "['account', 'speech', 'agenda', 'socialist', 'pleas', 'free', 'social', 'mani', 'read', 'twitter']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #47 GIVEN BY NMF:\n",
      "['thing', 'suprem', 'actual', 'dogma', 'histori', 'ideolog', 'court', 'doe', 'fals', 'ani']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #48 GIVEN BY NMF:\n",
      "['mike', 'togeth', 'happi', 'vice', 'class', 'capit', 'love', 'presid', 'dai', 'work']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #49 GIVEN BY NMF:\n",
      "['twitter', 'mani', 'thank', 'fight', 'educ', 'wrong', 'bia', 'real', 'todai', 'watch']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, topic in enumerate(nmf_model.components_):\n",
    "    print(f'THE TOP 10 WORDS FOR TOPIC #{index} GIVEN BY NMF:')\n",
    "    print([tfidf.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfc6d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 0/50\n",
      "['world', 'liber', 'leftist', 'trump polit', 'donaldtrump', 'femin', 'polit', 'liber leftist', 'polit donaldtrump', 'leftist femin', 'liber leftist femin', 'femin polit', 'leftist femin polit', 'femin polit donaldtrump', 'world trump', 'world trump polit', 'trump', 'polit new', 'new liber', 'trump polit new']\n",
      "k: 1/50\n",
      "['democrat', 'polit democrat', 'polit', 'biden', 'readi', 'readi polit', 'trump', 'readi polit democrat', 'joe', 'joe biden', 'add polit democrat', 'lead', 'final', 'team', 'victori', 'despit', 'offici', 'foreign', 'trump biden', 'win']\n",
      "k: 2/50\n",
      "['turn', 'everyon', 'understand', 'point', 'wonder', 'sad', 'problem', 'onc', 'thought', 'stupid', 'sure', 'shame', 'true', 'someon', 'complet', 'consid', 'absolut', 'hard', 'seen', 'famili']\n",
      "k: 3/50\n",
      "['republican', 'conserv', 'conserv republican', 'trump', 'polit conserv', 'trump polit conserv', 'polit conserv republican', 'republican liber', 'conserv republican liber', 'republican liber leftist', 'liber', 'donaldtrump', 'trump polit', 'wage', 'republican trump', 'liber conserv', 'republican democrat', 'patriot', 'trump conserv', 'trump donaldtrump']\n",
      "k: 4/50\n",
      "['biden', 'add', 'add polit', 'polit', 'presid', 'joe', 'joe biden', 'presid biden', 'presid joe', 'presid joe biden', 'post', 'york post', 'new york post', 'administr', 'biden administr', 'new york', 'york', 'add polit democrat', 'covid', 'vaccin']\n",
      "k: 5/50\n",
      "['commun', 'share', 'upcom', 'chat', 'click', 'share polit', 'chat polit', 'polit upcom', 'upcom commun', 'upcom commun chat', 'polit click', 'polit upcom commun', 'share polit upcom', 'commun chat polit', 'commun chat', 'chat polit click', 'polit', 'social', 'social commun', 'anarchi']\n",
      "k: 6/50\n",
      "['right', 'wing', 'right wing', 'alt', 'extrem right', 'right wing media', 'alt right', 'wing media', 'right polit', 'right wing polit', 'wing extrem', 'right right', 'wing polit', 'right wing extrem', 'wing right', 'thi right', 'right thing', 'trump right', 'wing right wing', 'right wrong']\n",
      "k: 7/50\n",
      "['trump', 'canada', 'liber', 'polit', 'social', 'conserv liber', 'ralli', 'liber polit', 'conserv', 'resist', 'polit social', 'conserv liber polit', 'canada conserv', 'new', 'canada conserv liber', 'liber polit social', 'social new', 'polit social new', 'trump trump', 'aka']\n",
      "k: 8/50\n",
      "['thei', 'thei thei', 'themselv', 'sai thei', 'thei sai', 'thei try', 'thei believ', 'tell', 'thei onli', 'believ', 'thei realli', 'thei alwai', 'actual', 'thei won', 'believ thei', 'trump thei', 'claim', 'alwai', 'thei care', 'thei got']\n",
      "k: 9/50\n",
      "['thi', 'week', 'thi week', 'gui', 'happen', 'thi gui', 'articl', 'thi year', 'thread', 'thi thi', 'piec', 'morn', 'weekend', 'thi articl', 'thi morn', 'end', 'seen', 'doe thi', 'thi point', 'thi man']\n",
      "k: 10/50\n",
      "['new', 'old', 'fake', 'report', 'citi', 'break', 'studi', 'year', 'local', 'yorker', 'new yorker', 'channel', 'accord', 'book', 'fake new', 'sourc', 'mayor', 'green', 'role', 'target']\n",
      "k: 11/50\n",
      "['polit', 'congress', 'senat', 'tax', 'econom', 'rep', 'hous', 'crisi', 'plan', 'fight', 'high', 'pass', 'push', 'spend', 'reform', 'school', 'demand', 'committe', 'public', 'budget']\n",
      "k: 12/50\n",
      "['better', 'self', 'human', 'poor', 'speak', 'feel', 'ignor', 'becom', 'dear', 'rest', 'mind', 'fail', 'societi', 'lot', 'person', 'life', 'noth', 'attent', 'truth', 'sick']\n",
      "k: 13/50\n",
      "['white', 'hous', 'white hous', 'press', 'trump', 'hous watch', 'white hous watch', 'biden readi', 'biden readi polit', 'watch', 'larg', 'black', 'male', 'secretari', 'decal', 'hous press', 'white hous press', 'press secretari', 'trump readi', 'supremaci']\n",
      "k: 14/50\n",
      "['media', 'social media', 'stori', 'narr', 'cover', 'social', 'journalist', 'journal', 'press', 'coverag', 'new media', 'audienc', 'truth', 'main', 'manipul', 'liber media', 'media propaganda', 'altern', 'conserv media', 'media thei']\n",
      "k: 15/50\n",
      "['like', 'debat', 'like thi', 'debat polit', 'like thei', 'debat polit democrat', 'look like', 'look', 'thei like', 'presidenti debat', 'like trump', 'presidenti', 'act', 'sound', 'act like', 'presidenti debat polit', 'trump like', 'media like', 'convent', 'thi like']\n",
      "k: 16/50\n",
      "['add', 'add polit', 'trump', 'polit', 'senat', 'presid trump', 'china', 'border', 'administr', 'impeach', 'presid', 'sen', 'trump administr', 'gener', 'rep', 'depart', 'attornei', 'compani', 'alli', 'said']\n",
      "k: 17/50\n",
      "['left', 'left wing', 'wing', 'left right', 'far left', 'lean', 'socialist', 'polit', 'right left', 'bird', 'wing polit', 'left wing polit', 'user', 'labour', 'center', 'left polit', 'polit commun', 'wing polit commun', 'centrist', 'radic']\n",
      "k: 18/50\n",
      "['peopl', 'peopl like', 'kill', 'enemi', 'peopl thei', 'mani peopl', 'mani', 'black peopl', 'white peopl', 'million', 'peopl polit', 'truli', 'peopl want', 'die', 'kill peopl', 'lot', 'enemi peopl', 'million peopl', 'peopl right', 'onli peopl']\n",
      "k: 19/50\n",
      "['vote', 'major', 'candid', 'polit polit', 'hypocrit', 'polit', 'voter', 'govern polit', 'ballot', 'polit vote', 'blue', 'count', 'vote presid', 'shall', 'govern polit polit', 'polit polit vote', 'independ', 'protect', 'popular', 'govern']\n",
      "k: 20/50\n",
      "['polit', 'sander', 'awai', 'correct', 'view', 'promot', 'link', 'trump', 'power', 'warren', 'sen', 'afternoon', 'afternoon link', 'view polit', 'correct view polit', 'promot correct view', 'promot correct', 'correct view', 'wall', 'report']\n",
      "k: 21/50\n",
      "['new', 'fox', 'post', 'fox new', 'poll', 'polit', 'biden polit', 'new polit', 'york', 'new york', 'joe', 'primari', 'biden', 'biden polit democrat', 'kamala', 'joe biden', 'deal', 'endors', 'poll polit', 'trump new']\n",
      "k: 22/50\n",
      "['hate', 'violenc', 'fear', 'extrem', 'bigotri', 'bulli', 'divis', 'rhetor', 'hate violenc', 'discrimin', 'fear hate', 'intoler', 'hate bigotri', 'condemn', 'monger', 'bulli hate', 'extrem bulli', 'thei hate', 'extrem bulli hate', 'extrem hate']\n",
      "k: 23/50\n",
      "['parti', 'power', 'republican parti', 'democrat parti', 'leader', 'awai', 'tea', 'labour', 'tea parti', 'coalit', 'rule', 'labour parti', 'major', 'parti polit', 'result', 'gain', 'led', 'region', 'moder', 'parti leader']\n",
      "k: 24/50\n",
      "['polit', 'leader', 'immigr', 'russia', 'german', 'futur', 'meet', 'join', 'remain', 'parti', 'labour', 'polici', 'mai', 'movement', 'end', 'crimin', 'group', 'march', 'led', 'gain']\n",
      "k: 25/50\n",
      "['far', 'extrem', 'polic', 'rise', 'radic', 'far right', 'threat', 'terror', 'violent', 'danger', 'global', 'extremist', 'secur', 'grow', 'intellig', 'movement', 'worri', 'recent', 'research', 'concern']\n",
      "k: 26/50\n",
      "['anti', 'war', 'pro', 'immigr', 'protest', 'let', 'corpor', 'daili', 'union', 'street', 'civil', 'gai', 'choic', 'mail', 'boycott', 'telegraph', 'abort', 'sun', 'civil war', 'exploit']\n",
      "k: 27/50\n",
      "['think', 'group', 'member', 'tank', 'think tank', 'think thei', 'alec', 'written', 'influenc', 'strategi', 'polici', 'piec', 'thei think', 'institut', 'sever', 'think thi', 'public', 'fund', 'secret', 'peopl think']\n",
      "k: 28/50\n",
      "['time', 'everi', 'long', 'east', 'thi time', 'wast', 'morn', 'bai', 'ago', 'bai time', 'east bai', 'east bai time', 'befor', 'everi time', 'air', 'morn joe', 'long time', 'late', 'time polit', 'wast time']\n",
      "k: 29/50\n",
      "['elect', 'lost', 'night', 'gener', 'fraud', 'presidenti', 'polit', 'elect polit', 'colleg', 'trump elect', 'presid elect', 'elect readi', 'elect readi polit', 'win', 'won', 'presidenti elect', 'voter', 'befor', 'run', 'candid']\n",
      "k: 30/50\n",
      "['talk', 'won', 'try', 'befor', 'listen', 'doe', 'win', 'agenda', 'joebiden', 'alreadi', 'game', 'surpris', 'hack', 'offic', 'protect', 'evid', 'investig', 'typic', 'thing', 'hear']\n",
      "k: 31/50\n",
      "['realli', 'hypocrisi', 'blame', 'crazi', 'obama', 'funni', 'radio', 'progress', 'insan', 'barackobama', 'liber', 'talk', 'rush', 'worst', 'gun', 'host', 'yeah', 'tell', 'bush', 'miss']\n",
      "k: 32/50\n",
      "['need', 'start', 'help', 'realli', 'better', 'thei need', 'step', 'need stop', 'need know', 'stand', 'rid', 'stop', 'peopl need', 'thi need', 'realli need', 'remov', 'learn', 'need thi', 'need help', 'wake']\n",
      "k: 33/50\n",
      "['onli', 'govern', 'corrupt', 'brazil', 'coup', 'opposit', 'minist', 'possibl', 'current', 'small', 'hypocrisi', 'effect', 'prime', 'shut', 'prime minist', 'success', 'debat', 'bolivia', 'hope', 'monei']\n",
      "k: 34/50\n",
      "['support', 'know', 'becaus', 'stand', 'thei know', 'know thei', 'fascism', 'trump support', 'doe', 'alreadi', 'support trump', 'know thi', 'wear', 'alwai', 'want know', 'evil', 'thei support', 'bet', 'support thi', 'probabl']\n",
      "k: 35/50\n",
      "['obama', 'campaign', 'black', 'conspiraci', 'rememb', 'dure', 'trump', 'rais', 'trump campaign', 'outrag', 'went', 'send', 'illeg', 'biden campaign', 'campaign polit', 'mad', 'million', 'crazi', 'attack', 'dog']\n",
      "k: 36/50\n",
      "['fascism', 'fascist', 'freedom', 'democraci', 'religi', 'base', 'nation', 'patriot', 'religion', 'cultur', 'peac', 'state', 'public', 'societi', 'constitut', 'histori', 'activ', 'evil', 'nationalist', 'authoritarian']\n",
      "k: 37/50\n",
      "['becaus', 'conserv', 'becaus thei', 'libertarian', 'republican', 'freedom', 'trump republican', 'reason', 'republican conserv', 'conserv trump', 'conserv polit', 'republican polit', 'onli', 'patriot', 'walkawai', 'donaldtrump', 'polit', 'conserv trump republican', 'trump republican conserv', 'follow']\n",
      "k: 38/50\n",
      "['man', 'care', 'follow', 'anyon', 'health', 'noth', 'woman', 'anyth', 'check', 'fact', 'abort', 'tweet', 'health care', 'els', 'gai', 'accus', 'sex', 'said', 'murder', 'ani']\n",
      "k: 39/50\n",
      "['veri', 'got', 'sai', 'pandem', 'labour', 'covid', 'hope', 'big', 'someth', 'cult', 'tori', 'stai', 'littl', 'bad', 'sorri', 'todai', 'million', 'soon', 'home', 'posit']\n",
      "k: 40/50\n",
      "['sai', 'terror', 'attack', 'extremist', 'terrorist', 'murder', 'respons', 'wait', 'domest', 'sinc', 'noth', 'shoot', 'mean', 'kill', 'report', 'anyth', 'dead', 'crime', 'mass', 'biggest']\n",
      "k: 41/50\n",
      "['wai', 'conspiraci', 'tori', 'rich', 'public', 'extrem', 'look', 'fund', 'tax', 'latest', 'case', 'guardian', 'work', 'educ', 'balanc', 'fox', 'theori', 'busi', 'feder', 'wors']\n",
      "k: 42/50\n",
      "['want', 'countri', 'nation', 'thi countri', 'thei want', 'control', 'law', 'hear', 'justic', 'rule', 'divid', 'destroi', 'bring', 'constitut', 'secur', 'democraci', 'realli', 'nation secur', 'fight', 'enforc']\n",
      "k: 43/50\n",
      "['good', 'anoth', 'look', 'let', 'great', 'job', 'run', 'bad', 'nut', 'leav', 'wai', 'red', 'lose', 'exampl', 'law', 'forward', 'come', 'thing', 'chanc', 'man']\n",
      "k: 44/50\n",
      "['racist', 'stop', 'racism', 'covid', 'danger', 'race', 'ignor', 'bigot', 'tell', 'fascist', 'black', 'covid polit', 'extremist', 'nigel', 'farag', 'nigel farag', 'hatr', 'xenophobia', 'misogynist', 'radic']\n",
      "k: 45/50\n",
      "['propaganda', 'come', 'state', 'believ', 'chang', 'climat', 'said', 'video', 'god', 'monei', 'gun', 'machin', 'watch', 'scienc', 'save', 'death', 'climat chang', 'spread', 'russia', 'arm']\n",
      "k: 46/50\n",
      "['twitter', 'read', 'mani', 'social', 'free', 'pleas', 'socialist', 'agenda', 'speech', 'account', 'truth', 'block', 'push', 'platform', 'try', 'follow', 'censorship', 'free speech', 'ban', 'remov']\n",
      "k: 47/50\n",
      "['ani', 'fals', 'doe', 'court', 'ideolog', 'histori', 'dogma', 'actual', 'suprem', 'thing', 'suprem court', 'evangel', 'teach', 'truth', 'lie', 'claim', 'case', 'realiti', 'wai', 'god']\n",
      "k: 48/50\n",
      "['work', 'dai', 'presid', 'love', 'capit', 'class', 'vice', 'happi', 'togeth', 'mike', 'live', 'penc', 'everi', 'presid polit', 'presid trump', 'vice presid', 'earth', 'wealth', 'hard', 'kamala']\n",
      "k: 49/50\n",
      "['watch', 'todai', 'real', 'bia', 'wrong', 'educ', 'fight', 'thank', 'mani', 'twitter', 'year', 'best', 'economi', 'spin', 'alwai', 'watch thi', 'episod', 'walkawai', 'believ', 'seri']\n",
      "num topics:  50\n",
      "Topic Coherence is: [143.26343022548988, 27.489543846257654, 4.711392234497429, 42.92169487419654, 68.46934573483826, 76.90012674961596, -15.041548515682123, 30.449991255729973, -10.174177434568065, -55.605527863879416, -27.035072056391034, 1.490307243509766, 2.6439718816752427, -39.76789502314109, -14.843257249972764, -63.12025162848644, 13.36157813466184, -26.053344910397588, -54.22947614660347, -7.2023906632761, -26.24130067876524, 11.746460460392253, -18.565116501186672, -31.799341462834064, -0.7269444983530705, 15.159085085223499, 6.463211731683094, -10.259990634941037, -22.215421971833965, -0.8166438636255668, -3.118166781739012, -11.449722642171293, -28.107150512522697, -15.147782393590758, -9.619689647698536, -22.004756233880194, 11.30685727347898, 15.252155604763733, 1.8608814537478904, 2.1603223737015527, 9.943993535284472, -3.04023177636728, -3.265427208311134, 4.694103681624791, -8.684639683357961, -0.33456183257272265, 9.257921054562242, 10.053519875602047, -17.516787705860075, 9.200068993979858]\n"
     ]
    }
   ],
   "source": [
    "seed = \"immigr\"\n",
    "tc,ind_seed = get_topic_coherence(nmf, processed_data_test, tfidf.get_feature_names(), seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7ba1b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=50, doc_topic_prior=.01)\n",
    "lda_topics = lda_model.fit_transform(tf_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98ae248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_df = pd.DataFrame(lda_model.components_, columns=tf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c2c8d6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 10 WORDS FOR TOPIC #0 GIVEN BY LDA:\n",
      "['joe biden', 'post', 'joe', 'hous', 'new', 'presid', 'biden', 'polit', 'add polit', 'add']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #1 GIVEN BY LDA:\n",
      "['polit', 'like', 'capit', 'right', 'new', 'media', 'trump', 'peopl', 'thei', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #2 GIVEN BY LDA:\n",
      "['good', 'left', 'support', 'sai', 'time', 'thi', 'peopl', 'polit', 'thei', 'trump']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #3 GIVEN BY LDA:\n",
      "['new', 'biden', 'campaign', 'readi polit democrat', 'readi polit', 'trump', 'readi', 'polit democrat', 'democrat', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #4 GIVEN BY LDA:\n",
      "['trump', 'new', 'like', 'time', 'right', 'thi', 'media', 'peopl', 'polit', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #5 GIVEN BY LDA:\n",
      "['obama', 'know', 'media', 'becaus', 'left', 'thei', 'right', 'like', 'thi', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #6 GIVEN BY LDA:\n",
      "['freedom', 'like', 'republican', 'thei', 'trump republican', 'conserv trump', 'polit', 'conserv', 'trump', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #7 GIVEN BY LDA:\n",
      "['think', 'media', 'want', 'right', 'peopl', 'polit', 'trump', 'like', 'thi', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #8 GIVEN BY LDA:\n",
      "['parti', 'polit', 'trump', 'peopl', 'right', 'new', 'like', 'vote', 'thei', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #9 GIVEN BY LDA:\n",
      "['like', 'anti', 'suprem', 'suprem court', 'court', 'peopl', 'thei', 'trump', 'thi', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #10 GIVEN BY LDA:\n",
      "['republican', 'need', 'want', 'peopl', 'polit', 'new', 'like', 'trump', 'thei', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #11 GIVEN BY LDA:\n",
      "['need', 'new', 'left', 'trump', 'like', 'right', 'peopl', 'thei', 'thi', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #12 GIVEN BY LDA:\n",
      "['peopl', 'let', 'telegraph', 'mail', 'racist', 'thi', 'new', 'media', 'anti', 'pro']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #13 GIVEN BY LDA:\n",
      "['media', 'left', 'hate', 'vote', 'peopl', 'new', 'thi', 'thei', 'polit', 'trump']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #14 GIVEN BY LDA:\n",
      "['conserv', 'new', 'nation', 'peopl', 'right', 'like', 'polit', 'trump', 'thei', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #15 GIVEN BY LDA:\n",
      "['readi polit', 'readi', 'elect', 'joe biden', 'joe', 'trump', 'biden', 'polit democrat', 'democrat', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #16 GIVEN BY LDA:\n",
      "['time', 'know', 'onli', 'polit', 'like', 'media', 'right', 'thei', 'trump', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #17 GIVEN BY LDA:\n",
      "['onli', 'extrem', 'right', 'like', 'hate', 'trump', 'polit', 'peopl', 'thei', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #18 GIVEN BY LDA:\n",
      "['becaus', 'anti', 'white', 'decal', 'new', 'polit', 'right', 'thi', 'trump', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #19 GIVEN BY LDA:\n",
      "['left wing polit', 'commun', 'onli', 'wing', 'peopl', 'left', 'trump', 'polit', 'thi', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #20 GIVEN BY LDA:\n",
      "['anti', 'peopl', 'want', 'elect', 'media', 'thi', 'new', 'thei', 'trump', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #21 GIVEN BY LDA:\n",
      "['ani', 'media', 'peopl', 'social', 'new', 'right', 'need', 'polit', 'thi', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #22 GIVEN BY LDA:\n",
      "['media', 'work', 'think', 'parti', 'peopl', 'like', 'trump', 'polit', 'thi', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #23 GIVEN BY LDA:\n",
      "['media', 'stop', 'left', 'peopl', 'like', 'polit', 'new', 'thi', 'trump', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #24 GIVEN BY LDA:\n",
      "['time', 'govern polit', 'trump', 'presid', 'govern', 'polit polit', 'vote', 'thei', 'thi', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #25 GIVEN BY LDA:\n",
      "['know', 'time', 'think', 'like', 'thei', 'peopl', 'becaus', 'polit', 'trump', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #26 GIVEN BY LDA:\n",
      "['new', 'onli', 'like', 'extrem', 'wing', 'left', 'polit', 'thi', 'right', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #27 GIVEN BY LDA:\n",
      "['conserv', 'like', 'left', 'thi', 'thei', 'polit', 'right', 'new', 'trump', 'media']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #28 GIVEN BY LDA:\n",
      "['right', 'onli', 'govern', 'need', 'like', 'polit', 'peopl', 'trump', 'thi', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #29 GIVEN BY LDA:\n",
      "['thi', 'media', 'thei', 'left wing', 'left', 'polit', 'trump', 'right', 'right wing', 'wing']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #30 GIVEN BY LDA:\n",
      "['wing', 'trump', 'terror', 'new', 'thei', 'peopl', 'like', 'polit', 'right', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #31 GIVEN BY LDA:\n",
      "['hate bigotri', 'add polit', 'add', 'hate', 'vote', 'peopl', 'thi', 'thei', 'trump', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #32 GIVEN BY LDA:\n",
      "['chat polit', 'share polit', 'chat', 'commun', 'click', 'thi', 'share', 'upcom', 'trump', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #33 GIVEN BY LDA:\n",
      "['onli', 'wing', 'anti', 'thi', 'radic', 'right', 'trump', 'peopl', 'polit', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #34 GIVEN BY LDA:\n",
      "['like', 'vote', 'new', 'right', 'peopl', 'parti', 'trump', 'thi', 'thei', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #35 GIVEN BY LDA:\n",
      "['leftist femin', 'polit donaldtrump', 'liber leftist', 'femin', 'trump polit', 'leftist', 'liber', 'donaldtrump', 'trump', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #36 GIVEN BY LDA:\n",
      "['hate', 'need', 'think', 'polit', 'right', 'peopl', 'like', 'trump', 'thi', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #37 GIVEN BY LDA:\n",
      "['time', 'left', 'right', 'onli', 'peopl', 'media', 'polit', 'thei', 'thi', 'trump']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #38 GIVEN BY LDA:\n",
      "['onli', 'media', 'new', 'conserv', 'thi', 'like', 'peopl', 'trump', 'polit', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #39 GIVEN BY LDA:\n",
      "['conserv liber polit', 'canada', 'liber polit', 'conserv', 'social', 'conserv liber', 'new', 'liber', 'polit', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #40 GIVEN BY LDA:\n",
      "['support', 'left', 'time', 'parti', 'peopl', 'like', 'right', 'thei', 'polit', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #41 GIVEN BY LDA:\n",
      "['like', 'know', 'think', 'wing', 'onli', 'becaus', 'trump', 'right', 'thi', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #42 GIVEN BY LDA:\n",
      "['nation', 'support', 'need', 'polit', 'right', 'like', 'peopl', 'trump', 'thi', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #43 GIVEN BY LDA:\n",
      "['white hous watch', 'work', 'time', 'hous watch', 'right', 'thei', 'thi', 'media', 'trump', 'polit']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #44 GIVEN BY LDA:\n",
      "['right', 'propaganda', 'member', 'thei', 'like', 'peopl', 'think tank', 'tank', 'thi', 'think']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #45 GIVEN BY LDA:\n",
      "['hate', 'time', 'becaus', 'vote', 'like', 'peopl', 'trump', 'polit', 'thi', 'thei']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #46 GIVEN BY LDA:\n",
      "['extrem bulli hate', 'extrem bulli', 'cherri', 'bulli hate', 'trump', 'like', 'thei', 'bulli', 'polit', 'hate']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #47 GIVEN BY LDA:\n",
      "['media bia', 'educ', 'view', 'power', 'trump', 'bia', 'thei', 'media', 'polit', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #48 GIVEN BY LDA:\n",
      "['peopl', 'look', 'becaus', 'like', 'obama', 'media', 'vote', 'trump', 'polit', 'thi']\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #49 GIVEN BY LDA:\n",
      "['conserv', 'far', 'media', 'parti', 'trump', 'new', 'thei', 'thi', 'right', 'polit']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, topic in enumerate(lda_model.components_):\n",
    "    print(f'THE TOP 10 WORDS FOR TOPIC #{index} GIVEN BY LDA:')\n",
    "    print([tf_vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebd3db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naming topics \n",
    "#Topic0-  oil_gas_prices \n",
    "#Topic1 - grocery_store_workers\n",
    "#Topic2- toilet_paper_sanitiser\n",
    "#Topic3- online_shopping \n",
    "#Topic4- panic_buying_hoarding\n",
    "\n",
    "naming={0:'Topic0', 1:'Topic1', 2:'Topic2', 3:'Topic3', 4:'Topic4', 5:'Topic5', 6:'Topic6', 7:'Topic7',\n",
    "        8:'Topic8', 9:'Topic9', 10:'Topic10', 11:'Topic11', 12:'Topic12', 13:'Topic13', 14:'Topic14', 15:'Topic15',\n",
    "        16:'Topic16', 17:'Topic17', 18:'Topic18', 19:'Topic19', 20:'Topic20', 21:'Topic21', 22:'Topic22', 23:'Topic23',\n",
    "        24:'Topic24', 25:'Topic25', 26:'Topic26', 27:'Topic27', 28:'Topic28', 29:'Topic29', 30:'Topic30', 31:'Topic31',\n",
    "        32:'Topic32', 33:'Topic33', 34:'Topic34', 35:'Topic35', 36:'Topic36', 37:'Topic37', 38:'Topic38', 39:'Topic39',\n",
    "        40:'Topic40', 41:'Topic41', 42:'Topic42', 43:'Topic43', 44:'Topic44', 45:'Topic45', 46:'Topic46', 47:'Topic47',\n",
    "        48:'Topic48', 49:'Topic49'}\n",
    "\n",
    "result_test[5] = nmf_topics.argmax(axis=1)\n",
    "result_test[5] = result_test[5].map(naming)\n",
    "result_test[6] = result_test[4].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8cabd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6_left</th>\n",
       "      <th>6_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">leftwing</th>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>LeftWing_b</td>\n",
       "      <td>AOC, Bernice King Slam McCarthy for Saying MLK Would Oppose Critica... (Truthout)  Bernice King and Rep. Alexandria Ocasio-Cortez (D-New York) sharply criticized House Minorit...  Add your highlights:   #LeftWing #Politics...</td>\n",
       "      <td>, King Slam for Saying Would Oppose ... ( ) King and Rep . - Cortez ( D - New York ) sharply House ... Add your : # # Politics ...</td>\n",
       "      <td>[king, slam, sai, oppos, king, rep, cortez, new, york, sharpli, hous, add, polit]</td>\n",
       "      <td>Topic10</td>\n",
       "      <td>king slam sai oppos king rep cortez new york sharpli hous add polit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>LeftWing_b</td>\n",
       "      <td>Thousands in Cuba Protest Amid Deep Economic Crisis and Ongoing US ... (Truthout)  We go to Havana, Cuba, to look at what is behind protests that brought thousands of people i...  Add your highlights:   #LeftWing #Politics...</td>\n",
       "      <td>in Protest Amid Deep Economic Crisis and Ongoing US ... ( ) We go to , , to look at what is behind that brought of people i ... Add your : # # Politics ...</td>\n",
       "      <td>[protest, amid, deep, econom, crisi, ongo, look, brought, peopl, add, polit]</td>\n",
       "      <td>Topic18</td>\n",
       "      <td>protest amid deep econom crisi ongo look brought peopl add polit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>LeftWing_b</td>\n",
       "      <td>Biden Should Dismantle US Bases in Iraq and Bring the Troops Home (Truthout)  At Bagram Air Base, Afghan scrap merchants are already picking through the graveyard of U.S....  Add your highlights:   #LeftWing #Politics...</td>\n",
       "      <td>Biden Should Dismantle US Bases in and Bring the Home ( ) At Air Base , scrap are already through the graveyard of U . S .... Add your : # # Politics ...</td>\n",
       "      <td>[biden, dismantl, base, bring, home, air, base, scrap, alreadi, graveyard, add, polit]</td>\n",
       "      <td>Topic4</td>\n",
       "      <td>biden dismantl base bring home air base scrap alreadi graveyard add polit</td>\n",
       "      <td>-0.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>LeftWing_b</td>\n",
       "      <td>Sanders Calls $. Trillion Reconciliation Bill a \"Pivotal Moment\" ... (Truthout)  The Senate Democratic leadership agreed late Tuesday to push for a $. trillion legislative...  Add your highlights:   #LeftWing #Politics...</td>\n",
       "      <td>Sanders $. Trillion Reconciliation Bill a \" Pivotal Moment \" ... ( ) The Senate Democratic leadership agreed late to push for a $. trillion legislative ... Add your : # # Politics ...</td>\n",
       "      <td>[sander, trillion, reconcili, pivot, moment, senat, democrat, leadership, agre, late, push, trillion, legisl, add, polit]</td>\n",
       "      <td>Topic11</td>\n",
       "      <td>sander trillion reconcili pivot moment senat democrat leadership agre late push trillion legisl add polit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>LeftWing_b</td>\n",
       "      <td>Republicans Who Worked on Bipartisan Infrastructure Now Won't Com... (Truthout)  Several Senate Republicans who initially said they'd support the watered down, bipartisan ve...  Add your highlights:   #LeftWing #Politics...</td>\n",
       "      <td>Who Worked on Bipartisan Infrastructure Now Won ' t ... ( ) Several Senate who initially said they ' d support the watered down , bipartisan ... Add your : # # Politics ...</td>\n",
       "      <td>[work, bipartisan, infrastructur, won, sever, senat, initi, said, thei, support, water, bipartisan, add, polit]</td>\n",
       "      <td>Topic4</td>\n",
       "      <td>work bipartisan infrastructur won sever senat initi said thei support water bipartisan add polit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">rightwing</th>\n",
       "      <th>119513</th>\n",
       "      <td>2011-07-14</td>\n",
       "      <td>StarStuff_ivan</td>\n",
       "      <td>#Conservative State Legislatures that Upend Constitution And the #RightWing Ideologues That Fuel Their Fringe Ideas</td>\n",
       "      <td># Conservative State that Upend Constitution And the # That Fuel Their Fringe</td>\n",
       "      <td>[conserv, state, upend, constitut, fuel, fring]</td>\n",
       "      <td>Topic31</td>\n",
       "      <td>conserv state upend constitut fuel fring</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119514</th>\n",
       "      <td>2011-07-14</td>\n",
       "      <td>Brooklynwatch</td>\n",
       "      <td>#rightwing babble abt POTUS really sickening. #teaparty  Never heard any other POTUS called \"arrogant\" when dealing w/congress WHY? #race</td>\n",
       "      <td># babble really sickening . # Never any other \" arrogant \" when dealing w / congress WHY ? # race</td>\n",
       "      <td>[babbl, realli, sicken, ani, arrog, deal, congress, race]</td>\n",
       "      <td>Topic21</td>\n",
       "      <td>babbl realli sicken ani arrog deal congress race</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119518</th>\n",
       "      <td>2011-07-14</td>\n",
       "      <td>Scott23875</td>\n",
       "      <td>“@SkyNewsBreak: Sky sources: Daily Mail to increase cover price because of difficult advertising market and newsprint costs” ROFL #rightwing</td>\n",
       "      <td>“@ : Sky : Daily Mail to increase cover price because of difficult advertising market and newsprint ” #</td>\n",
       "      <td>[sky, daili, mail, increas, cover, price, becaus, difficult, advertis, market, newsprint]</td>\n",
       "      <td>Topic26</td>\n",
       "      <td>sky daili mail increas cover price becaus difficult advertis market newsprint</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119519</th>\n",
       "      <td>2011-07-14</td>\n",
       "      <td>Salbima</td>\n",
       "      <td>#ALEC Exposed: A Nationwide Blueprint for the #Rightwing #Takeover | Common Dreams:  via @AddThis #usa #politics</td>\n",
       "      <td># ALEC Exposed : A Nationwide Blueprint for the # # | Common : via @ # # politics</td>\n",
       "      <td>[alec, expos, nationwid, blueprint, common, polit]</td>\n",
       "      <td>Topic36</td>\n",
       "      <td>alec expos nationwid blueprint common polit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119520</th>\n",
       "      <td>2011-07-14</td>\n",
       "      <td>LiberaLLamp</td>\n",
       "      <td>@AngryVoters Educate yrself on #Obama  Haters &amp; #RightWing Sock Puppets Whine while #Liberals celebrate @LiberalPagan #p</td>\n",
       "      <td>@ Educate on # Obama &amp; # Sock Whine while # celebrate @ # p</td>\n",
       "      <td>[educ, obama, sock, whine, celebr]</td>\n",
       "      <td>Topic35</td>\n",
       "      <td>educ obama sock whine celebr</td>\n",
       "      <td>-0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109948 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0               1  \\\n",
       "leftwing  0       2021-07-14      LeftWing_b   \n",
       "          1       2021-07-14      LeftWing_b   \n",
       "          2       2021-07-14      LeftWing_b   \n",
       "          3       2021-07-14      LeftWing_b   \n",
       "          4       2021-07-14      LeftWing_b   \n",
       "...                      ...             ...   \n",
       "rightwing 119513  2011-07-14  StarStuff_ivan   \n",
       "          119514  2011-07-14   Brooklynwatch   \n",
       "          119518  2011-07-14      Scott23875   \n",
       "          119519  2011-07-14         Salbima   \n",
       "          119520  2011-07-14     LiberaLLamp   \n",
       "\n",
       "                                                                                                                                                                                                                                                   2  \\\n",
       "leftwing  0        AOC, Bernice King Slam McCarthy for Saying MLK Would Oppose Critica... (Truthout)  Bernice King and Rep. Alexandria Ocasio-Cortez (D-New York) sharply criticized House Minorit...  Add your highlights:   #LeftWing #Politics...   \n",
       "          1        Thousands in Cuba Protest Amid Deep Economic Crisis and Ongoing US ... (Truthout)  We go to Havana, Cuba, to look at what is behind protests that brought thousands of people i...  Add your highlights:   #LeftWing #Politics...   \n",
       "          2             Biden Should Dismantle US Bases in Iraq and Bring the Troops Home (Truthout)  At Bagram Air Base, Afghan scrap merchants are already picking through the graveyard of U.S....  Add your highlights:   #LeftWing #Politics...   \n",
       "          3            Sanders Calls $. Trillion Reconciliation Bill a \"Pivotal Moment\" ... (Truthout)  The Senate Democratic leadership agreed late Tuesday to push for a $. trillion legislative...  Add your highlights:   #LeftWing #Politics...   \n",
       "          4          Republicans Who Worked on Bipartisan Infrastructure Now Won't Com... (Truthout)  Several Senate Republicans who initially said they'd support the watered down, bipartisan ve...  Add your highlights:   #LeftWing #Politics...   \n",
       "...                                                                                                                                                                                                                                              ...   \n",
       "rightwing 119513                                                                                                                #Conservative State Legislatures that Upend Constitution And the #RightWing Ideologues That Fuel Their Fringe Ideas    \n",
       "          119514                                                                                           #rightwing babble abt POTUS really sickening. #teaparty  Never heard any other POTUS called \"arrogant\" when dealing w/congress WHY? #race   \n",
       "          119518                                                                                        “@SkyNewsBreak: Sky sources: Daily Mail to increase cover price because of difficult advertising market and newsprint costs” ROFL #rightwing   \n",
       "          119519                                                                                                                    #ALEC Exposed: A Nationwide Blueprint for the #Rightwing #Takeover | Common Dreams:  via @AddThis #usa #politics   \n",
       "          119520                                                                                                            @AngryVoters Educate yrself on #Obama  Haters & #RightWing Sock Puppets Whine while #Liberals celebrate @LiberalPagan #p   \n",
       "\n",
       "                                                                                                                                                                                                        3  \\\n",
       "leftwing  0                                                            , King Slam for Saying Would Oppose ... ( ) King and Rep . - Cortez ( D - New York ) sharply House ... Add your : # # Politics ...   \n",
       "          1                                   in Protest Amid Deep Economic Crisis and Ongoing US ... ( ) We go to , , to look at what is behind that brought of people i ... Add your : # # Politics ...   \n",
       "          2                                     Biden Should Dismantle US Bases in and Bring the Home ( ) At Air Base , scrap are already through the graveyard of U . S .... Add your : # # Politics ...   \n",
       "          3       Sanders $. Trillion Reconciliation Bill a \" Pivotal Moment \" ... ( ) The Senate Democratic leadership agreed late to push for a $. trillion legislative ... Add your : # # Politics ...   \n",
       "          4                  Who Worked on Bipartisan Infrastructure Now Won ' t ... ( ) Several Senate who initially said they ' d support the watered down , bipartisan ... Add your : # # Politics ...   \n",
       "...                                                                                                                                                                                                   ...   \n",
       "rightwing 119513                                                                                                            # Conservative State that Upend Constitution And the # That Fuel Their Fringe   \n",
       "          119514                                                                                        # babble really sickening . # Never any other \" arrogant \" when dealing w / congress WHY ? # race   \n",
       "          119518                                                                                  “@ : Sky : Daily Mail to increase cover price because of difficult advertising market and newsprint ” #   \n",
       "          119519                                                                                                        # ALEC Exposed : A Nationwide Blueprint for the # # | Common : via @ # # politics   \n",
       "          119520                                                                                                                              @ Educate on # Obama & # Sock Whine while # celebrate @ # p   \n",
       "\n",
       "                                                                                                                                          4  \\\n",
       "leftwing  0                                               [king, slam, sai, oppos, king, rep, cortez, new, york, sharpli, hous, add, polit]   \n",
       "          1                                                    [protest, amid, deep, econom, crisi, ongo, look, brought, peopl, add, polit]   \n",
       "          2                                          [biden, dismantl, base, bring, home, air, base, scrap, alreadi, graveyard, add, polit]   \n",
       "          3       [sander, trillion, reconcili, pivot, moment, senat, democrat, leadership, agre, late, push, trillion, legisl, add, polit]   \n",
       "          4                 [work, bipartisan, infrastructur, won, sever, senat, initi, said, thei, support, water, bipartisan, add, polit]   \n",
       "...                                                                                                                                     ...   \n",
       "rightwing 119513                                                                            [conserv, state, upend, constitut, fuel, fring]   \n",
       "          119514                                                                  [babbl, realli, sicken, ani, arrog, deal, congress, race]   \n",
       "          119518                                  [sky, daili, mail, increas, cover, price, becaus, difficult, advertis, market, newsprint]   \n",
       "          119519                                                                         [alec, expos, nationwid, blueprint, common, polit]   \n",
       "          119520                                                                                         [educ, obama, sock, whine, celebr]   \n",
       "\n",
       "                        5  \\\n",
       "leftwing  0       Topic10   \n",
       "          1       Topic18   \n",
       "          2        Topic4   \n",
       "          3       Topic11   \n",
       "          4        Topic4   \n",
       "...                   ...   \n",
       "rightwing 119513  Topic31   \n",
       "          119514  Topic21   \n",
       "          119518  Topic26   \n",
       "          119519  Topic36   \n",
       "          119520  Topic35   \n",
       "\n",
       "                                                                                                                     6_left  \\\n",
       "leftwing  0                                             king slam sai oppos king rep cortez new york sharpli hous add polit   \n",
       "          1                                                protest amid deep econom crisi ongo look brought peopl add polit   \n",
       "          2                                       biden dismantl base bring home air base scrap alreadi graveyard add polit   \n",
       "          3       sander trillion reconcili pivot moment senat democrat leadership agre late push trillion legisl add polit   \n",
       "          4                work bipartisan infrastructur won sever senat initi said thei support water bipartisan add polit   \n",
       "...                                                                                                                     ...   \n",
       "rightwing 119513                                                                   conserv state upend constitut fuel fring   \n",
       "          119514                                                           babbl realli sicken ani arrog deal congress race   \n",
       "          119518                              sky daili mail increas cover price becaus difficult advertis market newsprint   \n",
       "          119519                                                                alec expos nationwid blueprint common polit   \n",
       "          119520                                                                               educ obama sock whine celebr   \n",
       "\n",
       "                  6_right  \n",
       "leftwing  0           NaN  \n",
       "          1           NaN  \n",
       "          2        -0.296  \n",
       "          3           NaN  \n",
       "          4           NaN  \n",
       "...                   ...  \n",
       "rightwing 119513    0.000  \n",
       "          119514      NaN  \n",
       "          119518      NaN  \n",
       "          119519      NaN  \n",
       "          119520   -0.250  \n",
       "\n",
       "[109948 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_sentiment = result_test.sample(n=50000)\n",
    "labeled_sentiment[6] = labeled_sentiment.apply(lambda row : sentiment_scores(row[2]), axis = 1)\n",
    "result_test.join(labeled_sentiment[6], how='left', lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcbb28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_value = result_test[2]\n",
    "second_value = result_test[5]\n",
    "list_topic_labeled_test = [first_value, second_value]\n",
    "df_topic_labeled_test = pd.DataFrame(list(zip(first_value, second_value)), columns =['Tweet', 'Topic_Name'])\n",
    "display = df_topic_labeled_test.set_index(['Topic_Name'])\n",
    "value = display.loc['Topic5']\n",
    "display = value.sample(n=1000)\n",
    "#for ele in display['Tweet']:\n",
    "    #print(ele)\n",
    "    #print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ccd39a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "words = result_test[1].drop_duplicates()\n",
    "indices = np.random.zipf(1.6, size=100000).astype(np.int) % len(words)\n",
    "tweets = np.array(words)[indices]\n",
    "\n",
    "tf_count = Counter(tweets)\n",
    "\n",
    "y = [count for tag, count in tf_count.most_common(25)]\n",
    "x = [tag for tag, count in tf_count.most_common(25)]\n",
    "\n",
    "plt.bar(x, y, color='crimson')\n",
    "plt.title(\"Term frequencies in Twitter Data\")\n",
    "plt.ylabel(\"Frequency (log scale)\")\n",
    "plt.yscale('log') # optionally set a log scale for the y-axis\n",
    "plt.xticks(rotation=90)\n",
    "for i, (tag, count) in enumerate(tf_count.most_common(25)):\n",
    "    plt.text(i, count, f' {count} ', rotation=90,\n",
    "             ha='center', va='top' if i < 10 else 'bottom', color='white' if i < 10 else 'black')\n",
    "#plt.xlim(-0.6, len(x)-0.4) # optionally set tighter x lims\n",
    "plt.xlim(-1.0, len(x)-0.25) # optionally set tighter x lims\n",
    "plt.tight_layout() # change the whitespace such that all labels fit nicely\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "105fbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = labeled_sentiment.iloc[:, 2].values\n",
    "features2 = labeled_sentiment.iloc[:, 4].values\n",
    "topic = labeled_sentiment.iloc[:, 5].values\n",
    "labels = labeled_sentiment.iloc[:, 6].values\n",
    "d = {'original_tweet': features1, 'identified_topic': topic, 'features1': features1, 'features2': features2, 'labels': labels}\n",
    "df = pd.DataFrame(data=d)\n",
    "df['features1'] = df['features1'].apply(lambda row: prepare(row))\n",
    "df['features2_sen'] = df['features2'].apply(lambda row: ' '.join(row))\n",
    "df['multiclass_labels'] = df['labels'].apply(lambda row: cont_to_multiclass(row))\n",
    "df['binary_labels'] = df['labels'].apply(lambda row: cont_to_binary(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffff14b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">leftwing</th>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>LeftWing_b</td>\n",
       "      <td>AOC, Bernice King Slam McCarthy for Saying MLK Would Oppose Critica... (Truthout)  Bernice King and Rep. Alexandria Ocasio-Cortez (D-New York) sharply criticized House Minorit...  Add your highlights:   #LeftWing #Politics...</td>\n",
       "      <td>, King Slam for Saying Would Oppose ... ( ) King and Rep . - Cortez ( D - New York ) sharply House ... Add your : # # Politics ...</td>\n",
       "      <td>[king, slam, sai, oppos, king, rep, cortez, new, york, sharpli, hous, add, polit]</td>\n",
       "      <td>Topic10</td>\n",
       "      <td>king slam sai oppos king rep cortez new york sharpli hous add polit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>LeftWing_b</td>\n",
       "      <td>Thousands in Cuba Protest Amid Deep Economic Crisis and Ongoing US ... (Truthout)  We go to Havana, Cuba, to look at what is behind protests that brought thousands of people i...  Add your highlights:   #LeftWing #Politics...</td>\n",
       "      <td>in Protest Amid Deep Economic Crisis and Ongoing US ... ( ) We go to , , to look at what is behind that brought of people i ... Add your : # # Politics ...</td>\n",
       "      <td>[protest, amid, deep, econom, crisi, ongo, look, brought, peopl, add, polit]</td>\n",
       "      <td>Topic18</td>\n",
       "      <td>protest amid deep econom crisi ongo look brought peopl add polit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>LeftWing_b</td>\n",
       "      <td>Biden Should Dismantle US Bases in Iraq and Bring the Troops Home (Truthout)  At Bagram Air Base, Afghan scrap merchants are already picking through the graveyard of U.S....  Add your highlights:   #LeftWing #Politics...</td>\n",
       "      <td>Biden Should Dismantle US Bases in and Bring the Home ( ) At Air Base , scrap are already through the graveyard of U . S .... Add your : # # Politics ...</td>\n",
       "      <td>[biden, dismantl, base, bring, home, air, base, scrap, alreadi, graveyard, add, polit]</td>\n",
       "      <td>Topic4</td>\n",
       "      <td>biden dismantl base bring home air base scrap alreadi graveyard add polit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>LeftWing_b</td>\n",
       "      <td>Sanders Calls $. Trillion Reconciliation Bill a \"Pivotal Moment\" ... (Truthout)  The Senate Democratic leadership agreed late Tuesday to push for a $. trillion legislative...  Add your highlights:   #LeftWing #Politics...</td>\n",
       "      <td>Sanders $. Trillion Reconciliation Bill a \" Pivotal Moment \" ... ( ) The Senate Democratic leadership agreed late to push for a $. trillion legislative ... Add your : # # Politics ...</td>\n",
       "      <td>[sander, trillion, reconcili, pivot, moment, senat, democrat, leadership, agre, late, push, trillion, legisl, add, polit]</td>\n",
       "      <td>Topic11</td>\n",
       "      <td>sander trillion reconcili pivot moment senat democrat leadership agre late push trillion legisl add polit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>LeftWing_b</td>\n",
       "      <td>Republicans Who Worked on Bipartisan Infrastructure Now Won't Com... (Truthout)  Several Senate Republicans who initially said they'd support the watered down, bipartisan ve...  Add your highlights:   #LeftWing #Politics...</td>\n",
       "      <td>Who Worked on Bipartisan Infrastructure Now Won ' t ... ( ) Several Senate who initially said they ' d support the watered down , bipartisan ... Add your : # # Politics ...</td>\n",
       "      <td>[work, bipartisan, infrastructur, won, sever, senat, initi, said, thei, support, water, bipartisan, add, polit]</td>\n",
       "      <td>Topic4</td>\n",
       "      <td>work bipartisan infrastructur won sever senat initi said thei support water bipartisan add polit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">rightwing</th>\n",
       "      <th>119513</th>\n",
       "      <td>2011-07-14</td>\n",
       "      <td>StarStuff_ivan</td>\n",
       "      <td>#Conservative State Legislatures that Upend Constitution And the #RightWing Ideologues That Fuel Their Fringe Ideas</td>\n",
       "      <td># Conservative State that Upend Constitution And the # That Fuel Their Fringe</td>\n",
       "      <td>[conserv, state, upend, constitut, fuel, fring]</td>\n",
       "      <td>Topic31</td>\n",
       "      <td>conserv state upend constitut fuel fring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119514</th>\n",
       "      <td>2011-07-14</td>\n",
       "      <td>Brooklynwatch</td>\n",
       "      <td>#rightwing babble abt POTUS really sickening. #teaparty  Never heard any other POTUS called \"arrogant\" when dealing w/congress WHY? #race</td>\n",
       "      <td># babble really sickening . # Never any other \" arrogant \" when dealing w / congress WHY ? # race</td>\n",
       "      <td>[babbl, realli, sicken, ani, arrog, deal, congress, race]</td>\n",
       "      <td>Topic21</td>\n",
       "      <td>babbl realli sicken ani arrog deal congress race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119518</th>\n",
       "      <td>2011-07-14</td>\n",
       "      <td>Scott23875</td>\n",
       "      <td>“@SkyNewsBreak: Sky sources: Daily Mail to increase cover price because of difficult advertising market and newsprint costs” ROFL #rightwing</td>\n",
       "      <td>“@ : Sky : Daily Mail to increase cover price because of difficult advertising market and newsprint ” #</td>\n",
       "      <td>[sky, daili, mail, increas, cover, price, becaus, difficult, advertis, market, newsprint]</td>\n",
       "      <td>Topic26</td>\n",
       "      <td>sky daili mail increas cover price becaus difficult advertis market newsprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119519</th>\n",
       "      <td>2011-07-14</td>\n",
       "      <td>Salbima</td>\n",
       "      <td>#ALEC Exposed: A Nationwide Blueprint for the #Rightwing #Takeover | Common Dreams:  via @AddThis #usa #politics</td>\n",
       "      <td># ALEC Exposed : A Nationwide Blueprint for the # # | Common : via @ # # politics</td>\n",
       "      <td>[alec, expos, nationwid, blueprint, common, polit]</td>\n",
       "      <td>Topic36</td>\n",
       "      <td>alec expos nationwid blueprint common polit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119520</th>\n",
       "      <td>2011-07-14</td>\n",
       "      <td>LiberaLLamp</td>\n",
       "      <td>@AngryVoters Educate yrself on #Obama  Haters &amp; #RightWing Sock Puppets Whine while #Liberals celebrate @LiberalPagan #p</td>\n",
       "      <td>@ Educate on # Obama &amp; # Sock Whine while # celebrate @ # p</td>\n",
       "      <td>[educ, obama, sock, whine, celebr]</td>\n",
       "      <td>Topic35</td>\n",
       "      <td>educ obama sock whine celebr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109948 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0               1  \\\n",
       "leftwing  0       2021-07-14      LeftWing_b   \n",
       "          1       2021-07-14      LeftWing_b   \n",
       "          2       2021-07-14      LeftWing_b   \n",
       "          3       2021-07-14      LeftWing_b   \n",
       "          4       2021-07-14      LeftWing_b   \n",
       "...                      ...             ...   \n",
       "rightwing 119513  2011-07-14  StarStuff_ivan   \n",
       "          119514  2011-07-14   Brooklynwatch   \n",
       "          119518  2011-07-14      Scott23875   \n",
       "          119519  2011-07-14         Salbima   \n",
       "          119520  2011-07-14     LiberaLLamp   \n",
       "\n",
       "                                                                                                                                                                                                                                                   2  \\\n",
       "leftwing  0        AOC, Bernice King Slam McCarthy for Saying MLK Would Oppose Critica... (Truthout)  Bernice King and Rep. Alexandria Ocasio-Cortez (D-New York) sharply criticized House Minorit...  Add your highlights:   #LeftWing #Politics...   \n",
       "          1        Thousands in Cuba Protest Amid Deep Economic Crisis and Ongoing US ... (Truthout)  We go to Havana, Cuba, to look at what is behind protests that brought thousands of people i...  Add your highlights:   #LeftWing #Politics...   \n",
       "          2             Biden Should Dismantle US Bases in Iraq and Bring the Troops Home (Truthout)  At Bagram Air Base, Afghan scrap merchants are already picking through the graveyard of U.S....  Add your highlights:   #LeftWing #Politics...   \n",
       "          3            Sanders Calls $. Trillion Reconciliation Bill a \"Pivotal Moment\" ... (Truthout)  The Senate Democratic leadership agreed late Tuesday to push for a $. trillion legislative...  Add your highlights:   #LeftWing #Politics...   \n",
       "          4          Republicans Who Worked on Bipartisan Infrastructure Now Won't Com... (Truthout)  Several Senate Republicans who initially said they'd support the watered down, bipartisan ve...  Add your highlights:   #LeftWing #Politics...   \n",
       "...                                                                                                                                                                                                                                              ...   \n",
       "rightwing 119513                                                                                                                #Conservative State Legislatures that Upend Constitution And the #RightWing Ideologues That Fuel Their Fringe Ideas    \n",
       "          119514                                                                                           #rightwing babble abt POTUS really sickening. #teaparty  Never heard any other POTUS called \"arrogant\" when dealing w/congress WHY? #race   \n",
       "          119518                                                                                        “@SkyNewsBreak: Sky sources: Daily Mail to increase cover price because of difficult advertising market and newsprint costs” ROFL #rightwing   \n",
       "          119519                                                                                                                    #ALEC Exposed: A Nationwide Blueprint for the #Rightwing #Takeover | Common Dreams:  via @AddThis #usa #politics   \n",
       "          119520                                                                                                            @AngryVoters Educate yrself on #Obama  Haters & #RightWing Sock Puppets Whine while #Liberals celebrate @LiberalPagan #p   \n",
       "\n",
       "                                                                                                                                                                                                        3  \\\n",
       "leftwing  0                                                            , King Slam for Saying Would Oppose ... ( ) King and Rep . - Cortez ( D - New York ) sharply House ... Add your : # # Politics ...   \n",
       "          1                                   in Protest Amid Deep Economic Crisis and Ongoing US ... ( ) We go to , , to look at what is behind that brought of people i ... Add your : # # Politics ...   \n",
       "          2                                     Biden Should Dismantle US Bases in and Bring the Home ( ) At Air Base , scrap are already through the graveyard of U . S .... Add your : # # Politics ...   \n",
       "          3       Sanders $. Trillion Reconciliation Bill a \" Pivotal Moment \" ... ( ) The Senate Democratic leadership agreed late to push for a $. trillion legislative ... Add your : # # Politics ...   \n",
       "          4                  Who Worked on Bipartisan Infrastructure Now Won ' t ... ( ) Several Senate who initially said they ' d support the watered down , bipartisan ... Add your : # # Politics ...   \n",
       "...                                                                                                                                                                                                   ...   \n",
       "rightwing 119513                                                                                                            # Conservative State that Upend Constitution And the # That Fuel Their Fringe   \n",
       "          119514                                                                                        # babble really sickening . # Never any other \" arrogant \" when dealing w / congress WHY ? # race   \n",
       "          119518                                                                                  “@ : Sky : Daily Mail to increase cover price because of difficult advertising market and newsprint ” #   \n",
       "          119519                                                                                                        # ALEC Exposed : A Nationwide Blueprint for the # # | Common : via @ # # politics   \n",
       "          119520                                                                                                                              @ Educate on # Obama & # Sock Whine while # celebrate @ # p   \n",
       "\n",
       "                                                                                                                                          4  \\\n",
       "leftwing  0                                               [king, slam, sai, oppos, king, rep, cortez, new, york, sharpli, hous, add, polit]   \n",
       "          1                                                    [protest, amid, deep, econom, crisi, ongo, look, brought, peopl, add, polit]   \n",
       "          2                                          [biden, dismantl, base, bring, home, air, base, scrap, alreadi, graveyard, add, polit]   \n",
       "          3       [sander, trillion, reconcili, pivot, moment, senat, democrat, leadership, agre, late, push, trillion, legisl, add, polit]   \n",
       "          4                 [work, bipartisan, infrastructur, won, sever, senat, initi, said, thei, support, water, bipartisan, add, polit]   \n",
       "...                                                                                                                                     ...   \n",
       "rightwing 119513                                                                            [conserv, state, upend, constitut, fuel, fring]   \n",
       "          119514                                                                  [babbl, realli, sicken, ani, arrog, deal, congress, race]   \n",
       "          119518                                  [sky, daili, mail, increas, cover, price, becaus, difficult, advertis, market, newsprint]   \n",
       "          119519                                                                         [alec, expos, nationwid, blueprint, common, polit]   \n",
       "          119520                                                                                         [educ, obama, sock, whine, celebr]   \n",
       "\n",
       "                        5  \\\n",
       "leftwing  0       Topic10   \n",
       "          1       Topic18   \n",
       "          2        Topic4   \n",
       "          3       Topic11   \n",
       "          4        Topic4   \n",
       "...                   ...   \n",
       "rightwing 119513  Topic31   \n",
       "          119514  Topic21   \n",
       "          119518  Topic26   \n",
       "          119519  Topic36   \n",
       "          119520  Topic35   \n",
       "\n",
       "                                                                                                                          6  \n",
       "leftwing  0                                             king slam sai oppos king rep cortez new york sharpli hous add polit  \n",
       "          1                                                protest amid deep econom crisi ongo look brought peopl add polit  \n",
       "          2                                       biden dismantl base bring home air base scrap alreadi graveyard add polit  \n",
       "          3       sander trillion reconcili pivot moment senat democrat leadership agre late push trillion legisl add polit  \n",
       "          4                work bipartisan infrastructur won sever senat initi said thei support water bipartisan add polit  \n",
       "...                                                                                                                     ...  \n",
       "rightwing 119513                                                                   conserv state upend constitut fuel fring  \n",
       "          119514                                                           babbl realli sicken ani arrog deal congress race  \n",
       "          119518                              sky daili mail increas cover price becaus difficult advertis market newsprint  \n",
       "          119519                                                                alec expos nationwid blueprint common polit  \n",
       "          119520                                                                               educ obama sock whine celebr  \n",
       "\n",
       "[109948 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a3448a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_tweet</th>\n",
       "      <th>identified_topic</th>\n",
       "      <th>features1</th>\n",
       "      <th>features2</th>\n",
       "      <th>labels</th>\n",
       "      <th>features2_sen</th>\n",
       "      <th>multiclass_labels</th>\n",
       "      <th>binary_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Supreme Court Case That Enshrined White Supremacy in Law  + LeftyBot #LeftWing #Politics</td>\n",
       "      <td>Topic47</td>\n",
       "      <td>supreme court case enshrined white supremacy law leftybot leftwing politics</td>\n",
       "      <td>[suprem, court, case, white, supremaci, law, polit]</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>suprem court case white supremaci law polit</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump claims doctors 'get more money' for COVID deaths   #LeftWing #Politics #democrat #bernie</td>\n",
       "      <td>Topic44</td>\n",
       "      <td>trump claims doctors get money covid deaths leftwing politics democrat bernie</td>\n",
       "      <td>[trump, monei, covid, polit, democrat]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>trump monei covid polit democrat</td>\n",
       "      <td>partly negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@zesty_leftwing We need to make the #rightwing aware of #trumps plan, but they are all hypnotized..</td>\n",
       "      <td>Topic32</td>\n",
       "      <td>zesty_leftwing need make rightwing aware trumps plan hypnotized</td>\n",
       "      <td>[zesti, leftw, need, awar, plan, thei]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>zesti leftw need awar plan thei</td>\n",
       "      <td>partly negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Curious_Kurz I think BillyBoy could use some unsolicited money advice...  And the @TheDCSentinel might enjoy piling onto this hilarious thread...the responses to this moron are gold! @samknight_one @SamSacks   #asshat #rightwing #idiot #millioninsparechange?</td>\n",
       "      <td>Topic9</td>\n",
       "      <td>curious_kurz think billyboy could use unsolicited money advice thedcsentinel might enjoy piling onto hilarious thread responses moron gold samknight_one samsacks asshat rightwing idiot millioninsparechange</td>\n",
       "      <td>[curiou, kurz, think, billyboi, unsolicit, monei, advic, enjoi, pile, thi, hilari, thread, thi, moron, gold, samknight, idiot]</td>\n",
       "      <td>-0.2540</td>\n",
       "      <td>curiou kurz think billyboi unsolicit monei advic enjoi pile thi hilari thread thi moron gold samknight idiot</td>\n",
       "      <td>partly negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RepJoeKennedy @realDonaldTrump Youre so #Corrupt condemning everything @realDonaldTrump does knowing darn well that #Trump didn't cause the #DemocratShutdown. YOU #Left &amp;amp; your spineless #Radical #Leftwing leaders who won't agree on #TheWall you already agreed upon for obumer. #Dems won't compromise an inch</td>\n",
       "      <td>Topic34</td>\n",
       "      <td>repjoekennedy realdonaldtrump youre corrupt condemning everything realdonaldtrump knowing darn well trump cause democratshutdown left amp spineless radical leftwing leaders agree thewall already agreed upon obumer dems compromise inch</td>\n",
       "      <td>[corrupt, condemn, everyth, doe, know, darn, trump, becaus, left, spineless, radic, won, agre, alreadi, agre, won, compromis, inch]</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>corrupt condemn everyth doe know darn trump becaus left spineless radic won agre alreadi agre won compromis inch</td>\n",
       "      <td>partly positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>So tired of fighting lies from people so invested that they lose integrity. Dear #rightwing can't we just argue the issues please.</td>\n",
       "      <td>Topic18</td>\n",
       "      <td>tired fighting lies people invested lose integrity dear rightwing argue issues please</td>\n",
       "      <td>[tire, fight, peopl, thei, lose, integr, dear, argu, pleas]</td>\n",
       "      <td>-0.4443</td>\n",
       "      <td>tire fight peopl thei lose integr dear argu pleas</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>@WAtoday Endangered species hunted in Australia daily but no one gives a crap because they the #WokeMob #Greens #leftwing say it's traditional which is bullshit no need for it plenty of food around with no need for this #auspol</td>\n",
       "      <td>Topic32</td>\n",
       "      <td>watoday endangered species hunted australia daily one gives crap wokemob greens leftwing say traditional bullshit need plenty food around need auspol</td>\n",
       "      <td>[speci, daili, crap, becaus, thei, sai, tradit, need, plenti, food, need, thi]</td>\n",
       "      <td>-0.9517</td>\n",
       "      <td>speci daili crap becaus thei sai tradit need plenti food need thi</td>\n",
       "      <td>highly negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>If anyone gets a copy of this shit newspaper, and you’re not sure what to do with it, it makes great litter box liner, outhouse toilet paper, and would be excellent for kindling!  #epochtimes #trash #racism #rightwing</td>\n",
       "      <td>Topic9</td>\n",
       "      <td>anyone gets copy shit newspaper sure makes great litter box liner outhouse toilet paper would excellent kindling epochtimes trash racism rightwing</td>\n",
       "      <td>[anyon, copi, thi, newspap, sure, great, litter, box, liner, outhous, toilet, paper, excel, kindl, trash, racism]</td>\n",
       "      <td>-0.4222</td>\n",
       "      <td>anyon copi thi newspap sure great litter box liner outhous toilet paper excel kindl trash racism</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>📷 😡😡😡😡 #Government #Politics #Political #Democrats #Republicans #Elections #Voting #TeaParty #LeftWing #RightWing #NotMyPresident #President #TwoFacedRepublicans #Hypocrisy #Hypocrite #Trump #DonaldTrump #FuckTrump #DumpTrump...</td>\n",
       "      <td>Topic19</td>\n",
       "      <td>government politics political democrats republicans elections voting teaparty leftwing rightwing notmypresident president twofacedrepublicans hypocrisy hypocrite trump donaldtrump fucktrump dumptrump</td>\n",
       "      <td>[govern, polit, polit, vote, presid, hypocrisi, hypocrit, trump, donaldtrump]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>govern polit polit vote presid hypocrisi hypocrit trump donaldtrump</td>\n",
       "      <td>partly negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Listen Up, It’s Me, Your Therapist Who Finally Got on Twitter  + LeftyBot #LeftWing #Politics</td>\n",
       "      <td>Topic46</td>\n",
       "      <td>listen therapist finally got twitter leftybot leftwing politics</td>\n",
       "      <td>[listen, therapist, final, got, twitter, polit]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>listen therapist final got twitter polit</td>\n",
       "      <td>partly negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                  original_tweet  \\\n",
       "0                                                                                                                                                                                                                                   The Supreme Court Case That Enshrined White Supremacy in Law  + LeftyBot #LeftWing #Politics   \n",
       "1                                                                                                                                                                                                                                 Trump claims doctors 'get more money' for COVID deaths   #LeftWing #Politics #democrat #bernie   \n",
       "2                                                                                                                                                                                                                           @zesty_leftwing We need to make the #rightwing aware of #trumps plan, but they are all hypnotized..    \n",
       "3                                                           @Curious_Kurz I think BillyBoy could use some unsolicited money advice...  And the @TheDCSentinel might enjoy piling onto this hilarious thread...the responses to this moron are gold! @samknight_one @SamSacks   #asshat #rightwing #idiot #millioninsparechange?    \n",
       "4       @RepJoeKennedy @realDonaldTrump Youre so #Corrupt condemning everything @realDonaldTrump does knowing darn well that #Trump didn't cause the #DemocratShutdown. YOU #Left &amp; your spineless #Radical #Leftwing leaders who won't agree on #TheWall you already agreed upon for obumer. #Dems won't compromise an inch   \n",
       "...                                                                                                                                                                                                                                                                                                                          ...   \n",
       "49995                                                                                                                                                                                         So tired of fighting lies from people so invested that they lose integrity. Dear #rightwing can't we just argue the issues please.   \n",
       "49996                                                                                       @WAtoday Endangered species hunted in Australia daily but no one gives a crap because they the #WokeMob #Greens #leftwing say it's traditional which is bullshit no need for it plenty of food around with no need for this #auspol    \n",
       "49997                                                                                                 If anyone gets a copy of this shit newspaper, and you’re not sure what to do with it, it makes great litter box liner, outhouse toilet paper, and would be excellent for kindling!  #epochtimes #trash #racism #rightwing    \n",
       "49998                                                                                      📷 😡😡😡😡 #Government #Politics #Political #Democrats #Republicans #Elections #Voting #TeaParty #LeftWing #RightWing #NotMyPresident #President #TwoFacedRepublicans #Hypocrisy #Hypocrite #Trump #DonaldTrump #FuckTrump #DumpTrump...    \n",
       "49999                                                                                                                                                                                                                              Listen Up, It’s Me, Your Therapist Who Finally Got on Twitter  + LeftyBot #LeftWing #Politics   \n",
       "\n",
       "      identified_topic  \\\n",
       "0              Topic47   \n",
       "1              Topic44   \n",
       "2              Topic32   \n",
       "3               Topic9   \n",
       "4              Topic34   \n",
       "...                ...   \n",
       "49995          Topic18   \n",
       "49996          Topic32   \n",
       "49997           Topic9   \n",
       "49998          Topic19   \n",
       "49999          Topic46   \n",
       "\n",
       "                                                                                                                                                                                                                                        features1  \\\n",
       "0                                                                                                                                                                     supreme court case enshrined white supremacy law leftybot leftwing politics   \n",
       "1                                                                                                                                                                   trump claims doctors get money covid deaths leftwing politics democrat bernie   \n",
       "2                                                                                                                                                                                 zesty_leftwing need make rightwing aware trumps plan hypnotized   \n",
       "3                                   curious_kurz think billyboy could use unsolicited money advice thedcsentinel might enjoy piling onto hilarious thread responses moron gold samknight_one samsacks asshat rightwing idiot millioninsparechange   \n",
       "4      repjoekennedy realdonaldtrump youre corrupt condemning everything realdonaldtrump knowing darn well trump cause democratshutdown left amp spineless radical leftwing leaders agree thewall already agreed upon obumer dems compromise inch   \n",
       "...                                                                                                                                                                                                                                           ...   \n",
       "49995                                                                                                                                                       tired fighting lies people invested lose integrity dear rightwing argue issues please   \n",
       "49996                                                                                       watoday endangered species hunted australia daily one gives crap wokemob greens leftwing say traditional bullshit need plenty food around need auspol   \n",
       "49997                                                                                          anyone gets copy shit newspaper sure makes great litter box liner outhouse toilet paper would excellent kindling epochtimes trash racism rightwing   \n",
       "49998                                     government politics political democrats republicans elections voting teaparty leftwing rightwing notmypresident president twofacedrepublicans hypocrisy hypocrite trump donaldtrump fucktrump dumptrump   \n",
       "49999                                                                                                                                                                             listen therapist finally got twitter leftybot leftwing politics   \n",
       "\n",
       "                                                                                                                                 features2  \\\n",
       "0                                                                                      [suprem, court, case, white, supremaci, law, polit]   \n",
       "1                                                                                                   [trump, monei, covid, polit, democrat]   \n",
       "2                                                                                                   [zesti, leftw, need, awar, plan, thei]   \n",
       "3           [curiou, kurz, think, billyboi, unsolicit, monei, advic, enjoi, pile, thi, hilari, thread, thi, moron, gold, samknight, idiot]   \n",
       "4      [corrupt, condemn, everyth, doe, know, darn, trump, becaus, left, spineless, radic, won, agre, alreadi, agre, won, compromis, inch]   \n",
       "...                                                                                                                                    ...   \n",
       "49995                                                                          [tire, fight, peopl, thei, lose, integr, dear, argu, pleas]   \n",
       "49996                                                       [speci, daili, crap, becaus, thei, sai, tradit, need, plenti, food, need, thi]   \n",
       "49997                    [anyon, copi, thi, newspap, sure, great, litter, box, liner, outhous, toilet, paper, excel, kindl, trash, racism]   \n",
       "49998                                                        [govern, polit, polit, vote, presid, hypocrisi, hypocrit, trump, donaldtrump]   \n",
       "49999                                                                                      [listen, therapist, final, got, twitter, polit]   \n",
       "\n",
       "       labels  \\\n",
       "0      0.5859   \n",
       "1      0.0000   \n",
       "2      0.0000   \n",
       "3     -0.2540   \n",
       "4      0.2709   \n",
       "...       ...   \n",
       "49995 -0.4443   \n",
       "49996 -0.9517   \n",
       "49997 -0.4222   \n",
       "49998  0.0000   \n",
       "49999  0.0000   \n",
       "\n",
       "                                                                                                          features2_sen  \\\n",
       "0                                                                           suprem court case white supremaci law polit   \n",
       "1                                                                                      trump monei covid polit democrat   \n",
       "2                                                                                       zesti leftw need awar plan thei   \n",
       "3          curiou kurz think billyboi unsolicit monei advic enjoi pile thi hilari thread thi moron gold samknight idiot   \n",
       "4      corrupt condemn everyth doe know darn trump becaus left spineless radic won agre alreadi agre won compromis inch   \n",
       "...                                                                                                                 ...   \n",
       "49995                                                                 tire fight peopl thei lose integr dear argu pleas   \n",
       "49996                                                 speci daili crap becaus thei sai tradit need plenti food need thi   \n",
       "49997                  anyon copi thi newspap sure great litter box liner outhous toilet paper excel kindl trash racism   \n",
       "49998                                               govern polit polit vote presid hypocrisi hypocrit trump donaldtrump   \n",
       "49999                                                                          listen therapist final got twitter polit   \n",
       "\n",
       "      multiclass_labels  binary_labels  \n",
       "0              positive              1  \n",
       "1       partly negative              0  \n",
       "2       partly negative              0  \n",
       "3       partly negative              0  \n",
       "4       partly positive              1  \n",
       "...                 ...            ...  \n",
       "49995          negative              0  \n",
       "49996   highly negative              0  \n",
       "49997          negative              0  \n",
       "49998   partly negative              0  \n",
       "49999   partly negative              0  \n",
       "\n",
       "[50000 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "233f5f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:00<00:00, 914213.97it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2051706.70it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1471582.35it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1510220.07it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2183214.31it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2377561.62it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2281025.46it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2372800.20it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1732324.47it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2342479.92it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2020280.33it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1809168.55it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2053756.13it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1609442.61it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2264816.35it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2375514.83it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1712561.96it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1780884.69it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1773865.09it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1986635.47it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1282285.32it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2102513.41it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1873293.43it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2213750.22it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1861289.41it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2123053.25it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1982635.00it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1671690.14it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1704101.08it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1741198.74it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2060171.91it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2095287.19it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2415238.97it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2322247.44it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2170043.77it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1347065.51it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1850009.26it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2059059.40it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1613777.29it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2229257.82it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2232437.73it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2043330.67it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1809902.39it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1610963.28it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2224693.69it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1460798.82it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1635321.00it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1503270.11it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1384935.22it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2308393.05it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1775081.26it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1864566.03it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2082884.24it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2206042.25it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2122881.32it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2467063.50it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2461330.45it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2443065.67it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1537185.91it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1608294.73it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1646129.09it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2387087.67it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.90, min_df=20, stop_words=stopwords.words('english'), ngram_range=(1,3))\n",
    "dtm = tfidf.fit_transform(df['features2_sen']).toarray()\n",
    "\n",
    "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=20, stop_words=stopwords.words('english'), ngram_range=(1,3))\n",
    "bow = bow_vectorizer.fit_transform(df['features2_sen']).toarray()\n",
    "\n",
    "test = np.concatenate((dtm, bow), axis=1)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, split=' ')\n",
    "tokenizer.fit_on_texts(df['features2_sen'].values)\n",
    "bow_tok = tokenizer.texts_to_sequences(df['features2_sen'])\n",
    "bow_tok = pad_sequences(bow_tok)\n",
    "\n",
    "tokenized_tweet = df['features2_sen'].apply(lambda x: x.split())\n",
    "model_w2v = gensim.models.Word2Vec(df['features2_sen'], vector_size=300, window=5, min_count=5, sg=1,\n",
    "                                   hs=0, negative=10, seed=42)\n",
    "model_w2v.train(tokenized_tweet, total_examples=len(df['features2_sen']), epochs=20)\n",
    "sent2vec = np.empty((len(tokenized_tweet), 300))\n",
    "for ele in range(len(tokenized_tweet)):\n",
    "    sen_length = len(tokenized_tweet[ele])\n",
    "    current_words = np.empty((sen_length, 300))\n",
    "    for word in range(sen_length):\n",
    "        current_words[word] = word_vector(model_w2v, tokenized_tweet[ele][word], 300)[0]\n",
    "    sent2vec[ele] = np.mean(current_words, axis=0)\n",
    "\n",
    "ft_model = FastText(tokenized_tweet, vector_size=300, window=50, min_count=5, sg=1)\n",
    "fasttext = np.zeros((len(tokenized_tweet), 300)) \n",
    "for ele in range(len(tokenized_tweet)):\n",
    "    sen_length = len(tokenized_tweet[ele])\n",
    "    current_words = np.empty((sen_length, 300))\n",
    "    for word in range(sen_length):\n",
    "        current_words[word] = (word_vector(ft_model, tokenized_tweet[ele][word], 300)[0])\n",
    "    fasttext[ele] = np.mean(current_words, axis=0)\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "train_tagged = df.apply(lambda row: TaggedDocument(words=row['features2'], tags=row['identified_topic']), axis=1)\n",
    "doc2vec_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=5, sample = 0, workers=cores)\n",
    "doc2vec_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "for epoch in range(30):\n",
    "    doc2vec_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    doc2vec_dbow.alpha -= 0.002\n",
    "    doc2vec_dbow.min_alpha = doc2vec_dbow.alpha\n",
    "doc2vec_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=5, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "doc2vec_dmm.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "for epoch in range(30):\n",
    "    doc2vec_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    doc2vec_dmm.alpha -= 0.002\n",
    "    doc2vec_dmm.min_alpha = doc2vec_dmm.alpha\n",
    "doc2vec = ConcatenatedDoc2Vec([doc2vec_dbow, doc2vec_dmm])\n",
    "doc2vec = get_vectors(doc2vec, train_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc87b428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109948/109948 [00:00<00:00, 1479702.93it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2332330.26it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2202795.97it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1963148.39it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2077547.68it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1950782.95it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1799476.09it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2026050.08it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2470298.57it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1932746.87it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1904066.29it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1838282.95it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2111091.80it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1883058.33it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2062458.18it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1868720.36it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2398116.14it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2273537.91it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2167052.80it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2108427.84it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2292161.24it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2342007.54it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1590816.17it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2229235.87it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2017540.73it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2412253.55it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2194963.93it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2044409.19it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2350614.66it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2468420.94it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2409342.26it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2370235.23it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1880800.42it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1472666.92it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 2200851.10it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1376636.51it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1340454.83it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1803762.52it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1817740.60it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1739709.88it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1791416.28it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1987096.14it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1789143.58it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1878134.78it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1848325.39it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1644786.38it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1888139.18it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1763082.31it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1771922.89it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1935878.67it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1864285.83it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1704120.05it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1794923.50it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1541356.39it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1746449.90it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1561116.37it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1732696.11it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1682477.61it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1476604.30it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1887961.39it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1782911.22it/s]\n",
      "100%|██████████| 109948/109948 [00:00<00:00, 1591793.59it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf2 = TfidfVectorizer(max_df=0.90, min_df=20, stop_words=stopwords.words('english'), ngram_range=(1,3))\n",
    "dtm2 = tfidf.fit_transform(result_test[6]).toarray()\n",
    "\n",
    "bow_vectorizer2 = CountVectorizer(max_df=0.90, min_df=20, stop_words=stopwords.words('english'), ngram_range=(1,3))\n",
    "bow2 = bow_vectorizer.fit_transform(result_test[6]).toarray()\n",
    "\n",
    "test2 = np.concatenate((dtm2, bow2), axis=1)\n",
    "\n",
    "tokenizer2 = Tokenizer(num_words=10000, split=' ')\n",
    "tokenizer2.fit_on_texts(result_test[6].values)\n",
    "bow_tok2 = tokenizer2.texts_to_sequences(result_test[6])\n",
    "bow_tok2 = pad_sequences(bow_tok2)\n",
    "\n",
    "tokenized_tweet2 = result_test[6].apply(lambda x: x.split())\n",
    "model_w2v2 = gensim.models.Word2Vec(result_test[6], vector_size=300, window=5, min_count=5, sg=1,\n",
    "                                   hs=0, negative=10, seed=42)\n",
    "model_w2v2.train(tokenized_tweet2, total_examples=len(result_test[6]), epochs=20)\n",
    "sent2vec2 = np.empty((len(tokenized_tweet2), 300))\n",
    "for ele in range(len(tokenized_tweet2)):\n",
    "    sen_length = len(tokenized_tweet2[ele])\n",
    "    current_words = np.empty((sen_length, 300))\n",
    "    for word in range(sen_length):\n",
    "        current_words[word] = word_vector(model_w2v2, tokenized_tweet2[ele][word], 300)[0]\n",
    "    sent2vec2[ele] = np.mean(current_words, axis=0)\n",
    "\n",
    "ft_model2 = FastText(tokenized_tweet2, vector_size=300, window=50, min_count=5, sg=1)\n",
    "fasttext2 = np.zeros((len(tokenized_tweet2), 300)) \n",
    "for ele in range(len(tokenized_tweet2)):\n",
    "    sen_length = len(tokenized_tweet2[ele])\n",
    "    current_words = np.empty((sen_length, 300))\n",
    "    for word in range(sen_length):\n",
    "        current_words[word] = (word_vector(ft_model2, tokenized_tweet2[ele][word], 300)[0])\n",
    "    fasttext2[ele] = np.mean(current_words, axis=0)\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "train_tagged2 = result_test.apply(lambda row: TaggedDocument(words=row[4], tags=row[5]), axis=1)\n",
    "doc2vec_dbow2 = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=5, sample = 0, workers=cores)\n",
    "doc2vec_dbow2.build_vocab([x for x in tqdm(train_tagged2.values)])\n",
    "for epoch in range(30):\n",
    "    doc2vec_dbow2.train(utils.shuffle([x for x in tqdm(train_tagged2.values)]), total_examples=len(train_tagged2.values), epochs=1)\n",
    "    doc2vec_dbow2.alpha -= 0.002\n",
    "    doc2vec_dbow2.min_alpha = doc2vec_dbow2.alpha\n",
    "doc2vec_dmm2 = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=5, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "doc2vec_dmm2.build_vocab([x for x in tqdm(train_tagged2.values)])\n",
    "for epoch in range(30):\n",
    "    doc2vec_dmm2.train(utils.shuffle([x for x in tqdm(train_tagged2.values)]), total_examples=len(train_tagged2.values), epochs=1)\n",
    "    doc2vec_dmm2.alpha -= 0.002\n",
    "    doc2vec_dmm2.min_alpha = doc2vec_dmm2.alpha\n",
    "doc2vec2 = ConcatenatedDoc2Vec([doc2vec_dbow2, doc2vec_dmm2])\n",
    "doc2vec2 = get_vectors(doc2vec2, train_tagged2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73b659af",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_array = np.hstack((dtm, bow, sent2vec, fasttext, doc2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "702d475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(embed_array, df['binary_labels'], test_size=0.1, random_state=42)\n",
    "X_train, y_train = smt.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8539438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = pd.DataFrame(np.empty((len(df['binary_labels']), 5)), columns=['dtm', 'bow', 'sent2vec', 'fasttext', 'doc2vec'])\n",
    "etc_pred = pd.DataFrame(np.empty((len(df['binary_labels']), 5)), columns=['dtm', 'bow', 'sent2vec', 'fasttext', 'doc2vec'])\n",
    "sgd_pred = pd.DataFrame(np.empty((len(df['binary_labels']), 5)), columns=['dtm', 'bow', 'sent2vec', 'fasttext', 'doc2vec'])\n",
    "xgb_pred = pd.DataFrame(np.empty((len(df['binary_labels']), 5)), columns=['dtm', 'bow', 'sent2vec', 'fasttext', 'doc2vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd2979b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dtm = X_train[:, 0:dtm.shape[1]]\n",
    "X_train_bow = X_train[:, dtm.shape[1]:(dtm.shape[1]+bow.shape[1])]\n",
    "X_train_w2v = X_train[:, (dtm.shape[1]+bow.shape[1]):(dtm.shape[1]+bow.shape[1]+sent2vec.shape[1])]\n",
    "X_train_ft = X_train[:, (dtm.shape[1]+bow.shape[1]+sent2vec.shape[1]):(dtm.shape[1]+bow.shape[1]+sent2vec.shape[1]+fasttext.shape[1])]\n",
    "X_train_d2v = X_train[:, (dtm.shape[1]+bow.shape[1]+sent2vec.shape[1]+fasttext.shape[1]):(dtm.shape[1]+bow.shape[1]+sent2vec.shape[1]+fasttext.shape[1]+doc2vec.shape[1])]\n",
    "X_test_dtm = X_test[:, 0:dtm.shape[1]]\n",
    "X_test_bow = X_test[:, dtm.shape[1]:(dtm.shape[1]+bow.shape[1])]\n",
    "X_test_w2v = X_test[:, (dtm.shape[1]+bow.shape[1]):(dtm.shape[1]+bow.shape[1]+sent2vec.shape[1])]\n",
    "X_test_ft = X_test[:, (dtm.shape[1]+bow.shape[1]+sent2vec.shape[1]):(dtm.shape[1]+bow.shape[1]+sent2vec.shape[1]+fasttext.shape[1])]\n",
    "X_test_d2v = X_test[:, (dtm.shape[1]+bow.shape[1]+sent2vec.shape[1]+fasttext.shape[1]):(dtm.shape[1]+bow.shape[1]+sent2vec.shape[1]+fasttext.shape[1]+doc2vec.shape[1])]\n",
    "d = {'dtm': list(X_train_dtm), 'bow': list(X_train_bow), 'w2v': list(X_train_w2v), 'ft': list(X_train_ft), 'd2v': list(X_train_d2v)}\n",
    "X_train = pd.DataFrame(data=d)\n",
    "d = {'dtm': list(X_test_dtm), 'bow': list(X_test_bow), 'w2v': list(X_test_w2v), 'ft': list(X_test_ft), 'd2v': list(X_test_d2v)}\n",
    "X_test = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221affd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Training: \n",
      "RandomForest: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c76e7aa836bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RandomForest: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrf_classifier_dtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrf_classifier_dtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_dtm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_classifier_dtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_dtm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mrf_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtm'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                                         indices=indices)\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \"\"\"\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('TF-IDF Training: ')\n",
    "X_train_dtm = X_train['dtm'].to_numpy()\n",
    "X_train_dtm = np.stack(X_train_dtm, axis=0)\n",
    "X_test_dtm = X_test['dtm'].to_numpy()\n",
    "X_test_dtm = np.stack(X_test_dtm, axis=0)\n",
    "\n",
    "print(\"RandomForest: \")\n",
    "rf_classifier_dtm = RandomForestClassifier(n_estimators=300, max_depth=300, random_state=42)\n",
    "rf_classifier_dtm.fit(X_train_dtm, y_train)\n",
    "predictions = rf_classifier_dtm.predict(X_test_dtm)\n",
    "rf_pred['dtm'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"ExtraTree: \")\n",
    "etc_dtm = ExtraTreesClassifier(n_estimators=300, random_state=42)\n",
    "etc_dtm.fit(X_train_dtm, y_train)\n",
    "predictions = etc_dtm.predict(X_test_dtm)\n",
    "etc_pred['dtm'] = predictions\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"StochasticGradientDescent: \")\n",
    "sgd_classifier_dtm = SGDClassifier(loss=\"hinge\", penalty=\"l1\")\n",
    "sgd_classifier_dtm.fit(X_train_dtm, y_train)\n",
    "predictions = sgd_classifier_dtm.predict(X_test_dtm)\n",
    "sgd_pred['dtm'] = predictions\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"XGBoost: \")\n",
    "xgb_classifier_dtm = XGBClassifier(n_estimator=200, learning_rate=0.1, eval_metric='mlogloss', random_state=42)\n",
    "xgb_classifier_dtm.fit(X_train_dtm, y_train)\n",
    "predictions = xgb_classifier_dtm.predict(X_test_dtm)\n",
    "xgb_pred['dtm'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35025d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BOW Training: ')\n",
    "X_train_bow = X_train['bow'].to_numpy()\n",
    "X_train_bow = np.stack(X_train_bow, axis=0)\n",
    "X_test_bow = X_test['bow'].to_numpy()\n",
    "X_test_bow = np.stack(X_test_bow, axis=0)\n",
    "\n",
    "print(\"RandomForest: \")\n",
    "rf_classifier_bow = RandomForestClassifier(n_estimators=300, max_depth=300, random_state=42)\n",
    "rf_classifier_bow.fit(X_train_bow, y_train)\n",
    "predictions = rf_classifier_bow.predict(X_test_bow)\n",
    "rf_pred['bow'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"ExtraTree: \")\n",
    "etc_bow = ExtraTreesClassifier(n_estimators=300, random_state=42)\n",
    "etc_bow.fit(X_train_bow, y_train)\n",
    "predictions = etc_bow.predict(X_test_bow)\n",
    "etc_pred['bow'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"StochasticGradientDescent: \")\n",
    "sgd_classifier_bow = SGDClassifier(loss=\"hinge\", penalty=\"l1\")\n",
    "sgd_classifier_bow.fit(X_train_bow, y_train)\n",
    "predictions = sgd_classifier_bow.predict(X_test_bow)\n",
    "sgd_pred['bow'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"XGBoost: \")\n",
    "xgb_classifier_bow = XGBClassifier(n_estimator=200, learning_rate=0.1, eval_metric='mlogloss', random_state=42)\n",
    "xgb_classifier_bow.fit(X_train_bow, y_train)\n",
    "predictions = xgb_classifier_bow.predict(X_test_bow)\n",
    "xgb_pred['bow'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sent2Vec Training: ')\n",
    "X_train_w2v = X_train['w2v'].to_numpy()\n",
    "X_train_w2v = np.stack(X_train_w2v, axis=0)\n",
    "X_test_w2v = X_test['w2v'].to_numpy()\n",
    "X_test_w2v = np.stack(X_test_w2v, axis=0)\n",
    "\n",
    "print(\"RandomForest: \")\n",
    "rf_classifier_w2v = RandomForestClassifier(n_estimators=300, max_depth=300, random_state=42)\n",
    "rf_classifier_w2v.fit(X_train_w2v, y_train)\n",
    "predictions = rf_classifier_w2v.predict(X_test_w2v)\n",
    "rf_pred['sent2vec'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"ExtraTree: \")\n",
    "etc_w2v = ExtraTreesClassifier(n_estimators=300, random_state=42)\n",
    "etc_w2v.fit(X_train_w2v, y_train)\n",
    "predictions = etc_w2v.predict(X_test_w2v)\n",
    "etc_pred['sent2vec'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"StochasticGradientDescent: \")\n",
    "sgd_classifier_w2v = SGDClassifier(loss=\"hinge\", penalty=\"l1\")\n",
    "sgd_classifier_w2v.fit(X_train_w2v, y_train)\n",
    "predictions = sgd_classifier_w2v.predict(X_test_w2v)\n",
    "sgd_pred['sent2vec'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"XGBoost: \")\n",
    "xgb_classifier_w2v = XGBClassifier(n_estimator=200, learning_rate=0.1, eval_metric='mlogloss', random_state=42)\n",
    "xgb_classifier_w2v.fit(X_train_w2v, y_train)\n",
    "predictions = xgb_classifier_w2v.predict(X_test_w2v)\n",
    "xgb_pred['sent2vec'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30408a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FastText Training: ')\n",
    "X_train_ft = X_train['ft'].to_numpy()\n",
    "X_train_ft = np.stack(X_train_ft, axis=0)\n",
    "X_test_ft = X_test['ft'].to_numpy()\n",
    "X_test_ft = np.stack(X_test_ft, axis=0)\n",
    "\n",
    "print(\"RandomForest: \")\n",
    "rf_classifier_ft = RandomForestClassifier(n_estimators=300, max_depth=300, random_state=42)\n",
    "rf_classifier_ft.fit(X_train_ft, y_train)\n",
    "predictions = rf_classifier_ft.predict(X_test_ft)\n",
    "rf_pred['fasttext'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"ExtraTree: \")\n",
    "etc_ft = ExtraTreesClassifier(n_estimators=300, random_state=42)\n",
    "etc_ft.fit(X_train_ft, y_train)\n",
    "predictions = etc_ft.predict(X_test_ft)\n",
    "etc_pred['fasttext'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"StochasticGradientDescent: \")\n",
    "sgd_classifier_ft = SGDClassifier(loss=\"hinge\", penalty=\"l1\")\n",
    "sgd_classifier_ft.fit(X_train_ft, y_train)\n",
    "predictions = sgd_classifier_ft.predict(X_test_ft)\n",
    "sgd_pred['fasttext'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"XGBoost: \")\n",
    "xgb_classifier_ft = XGBClassifier(n_estimator=200, learning_rate=0.1, eval_metric='mlogloss', random_state=42)\n",
    "xgb_classifier_ft.fit(X_train_ft, y_train)\n",
    "predictions = xgb_classifier_ft.predict(X_test_ft)\n",
    "xgb_pred['fasttext'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b48a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Doc2Vec Training: ')\n",
    "X_train_d2v = X_train['d2v'].to_numpy()\n",
    "X_train_d2v = np.stack(X_train_d2v, axis=0)\n",
    "X_test_d2v = X_test['d2v'].to_numpy()\n",
    "X_test_d2v = np.stack(X_test_d2v, axis=0)\n",
    "\n",
    "print(\"RandomForest: \")\n",
    "rf_classifier_d2v = RandomForestClassifier(n_estimators=300, max_depth=300, random_state=42)\n",
    "rf_classifier_d2v.fit(X_train_d2v, y_train)\n",
    "predictions = rf_classifier_d2v.predict(X_test_d2v)\n",
    "rf_pred['doc2vec'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"ExtraTree: \")\n",
    "etc_d2v = ExtraTreesClassifier(n_estimators=300, random_state=42)\n",
    "etc_d2v.fit(X_train_d2v, y_train)\n",
    "predictions = etc_d2v.predict(X_test_d2v)\n",
    "etc_pred['doc2vec'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"StochasticGradientDescent: \")\n",
    "sgd_classifier_d2v = SGDClassifier(loss=\"hinge\", penalty=\"l1\")\n",
    "sgd_classifier_d2v.fit(X_train_d2v, y_train)\n",
    "predictions = sgd_classifier_d2v.predict(X_test_d2v)\n",
    "sgd_pred['doc2vec'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"XGBoost: \")\n",
    "xgb_classifier_d2v = XGBClassifier(n_estimator=200, learning_rate=0.1, eval_metric='mlogloss', random_state=42)\n",
    "xgb_classifier_d2v.fit(X_train_d2v, y_train)\n",
    "predictions = xgb_classifier_d2v.predict(X_test_d2v)\n",
    "xgb_pred['doc2vec'] = predictions\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e7b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(rf_pred, df['binary_labels'], test_size=0.1, random_state=42)\n",
    "X_etc_train, X_etc_test, y_etc_train, y_etc_test = train_test_split(etc_pred, df['binary_labels'], test_size=0.1, random_state=42)\n",
    "X_sgd_train, X_sgd_test, y_sgd_train, y_sgd_test = train_test_split(sgd_pred, df['binary_labels'], test_size=0.1, random_state=42)\n",
    "X_xgb_train, X_xgb_test, y_xgb_train, y_xgb_test = train_test_split(xgb_pred, df['binary_labels'], test_size=0.1, random_state=42)\n",
    "\n",
    "rf_model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "rf_model.fit(X_rf_train, y_rf_train)\n",
    "predictions = rf_model.predict(X_rf_test)\n",
    "print(confusion_matrix(y_rf_test, predictions))\n",
    "print(classification_report(y_rf_test, predictions))\n",
    "print(accuracy_score(y_rf_test, predictions))\n",
    "\n",
    "etc_model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "etc_model.fit(X_etc_train, y_etc_train)\n",
    "predictions = etc_model.predict(X_etc_test)\n",
    "print(confusion_matrix(y_etc_test, predictions))\n",
    "print(classification_report(y_etc_test, predictions))\n",
    "print(accuracy_score(y_etc_test, predictions))\n",
    "\n",
    "sgd_model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "sgd_model.fit(X_sgd_train, y_sgd_train)\n",
    "predictions = sgd_model.predict(X_sgd_test)\n",
    "print(confusion_matrix(y_sgd_test, predictions))\n",
    "print(classification_report(y_sgd_test, predictions))\n",
    "print(accuracy_score(y_sgd_test, predictions))\n",
    "\n",
    "xgb_model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "xgb_model.fit(X_xgb_train, y_sgd_train)\n",
    "predictions = xgb_model.predict(X_xgb_test)\n",
    "print(confusion_matrix(y_xgb_test, predictions))\n",
    "print(classification_report(y_xgb_test, predictions))\n",
    "print(accuracy_score(y_xgb_test, predictions))\n",
    "\n",
    "\"\"\"\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "import copy\n",
    "model1 = rf_classifier_dtm\n",
    "model2 = rf_classifier_bow\n",
    "model3 = rf_classifier_w2v\n",
    "model4 = rf_classifier_ft\n",
    "model5 = rf_classifier_d2v\n",
    "eclf = EnsembleVoteClassifier(clfs=[model1, model2, model3, model4, model5], weights=[1,1,1], fit_base_estimators=False)\n",
    "\n",
    "labels = ['TF-IDF', 'BOW', 'W2V', 'FT', 'D2V']\n",
    "for clf, label in zip([model1, model2, model3, model4, model5, eclf], labels):\n",
    "    scores = model_selection.cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))\n",
    "    \n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "estimators = []\n",
    "model1 = rf_classifier_dtm\n",
    "estimators.append(('dtm', model1))\n",
    "model2 = rf_classifier_bow\n",
    "estimators.append(('bow', model2))\n",
    "model3 = rf_classifier_w2v\n",
    "estimators.append(('w2v', model3))\n",
    "model4 = rf_classifier_ft\n",
    "estimators.append(('ft', model4))\n",
    "model5 = rf_classifier_d2v\n",
    "estimators.append(('d2v', model5))\n",
    "\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b5f65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dtm, df['multiclass_labels'], test_size=0.1, random_state=42)\n",
    "\n",
    "X_train, y_train = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"RandomForest: \")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=300, max_depth=300, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "predictions = rf_classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"ExtraTree: \")\n",
    "etc = ExtraTreesClassifier(n_estimators=300, random_state=42)\n",
    "etc.fit(X_train, y_train)\n",
    "predictions = etc.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"StochasticGradientDescent: \")\n",
    "sgd_classifier = SGDClassifier(loss=\"hinge\", penalty=\"l1\")\n",
    "sgd_classifier.fit(X_train, y_train)\n",
    "predictions = sgd_classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"XGBoost: \")\n",
    "xgb_classifier = XGBClassifier(n_estimator=200, learning_rate=0.1, eval_metric='mlogloss', random_state=42)\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "predictions = xgb_classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting utility\n",
    "from IPython.display import clear_output\n",
    "class PlotLosses(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        \n",
    "        self.acc.append(logs.get('accuracy'))\n",
    "        self.val_acc.append(logs.get('val_accuracy'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        fig, axes = plt.subplots(1,2,figsize=(8,3))\n",
    "        \n",
    "        axes[0].plot(self.x, self.losses, label=\"Train loss\")\n",
    "        axes[0].plot(self.x, self.val_losses, label=\"Validation loss\")\n",
    "        axes[0].set_xlabel('Number of epochs')\n",
    "        axes[0].set_ylabel('Losses')\n",
    "        axes[0].legend()\n",
    "            \n",
    "        axes[1].plot(self.x, self.acc, label=\"Train accuracy\")\n",
    "        axes[1].plot(self.x, self.val_acc, label=\"Validation accuracy\")\n",
    "        axes[1].set_xlabel('Number of epochs')\n",
    "        axes[1].set_ylabel('Accuracy')\n",
    "        axes[1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424f89e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "input_size = 37\n",
    "vocab_size = 7125\n",
    "plot_losses = PlotLosses()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, embed_dim, input_length=input_size))\n",
    "\n",
    "model.add(Conv1D(20, 6, padding='same', activation='relu', kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Conv1D(20, 6, padding='same', activation='relu', kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(lstm_out, dropout=0.25, recurrent_dropout=0.25, kernel_regularizer=regularizers.l1_l2(l1=1e-6, l2=2e-6)))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cebaf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "Le = LabelEncoder()\n",
    "y = Le.fit_transform(df['binary_labels'])\n",
    "#X_train, X_test, y_train, y_test = train_test_split(bow_tok, y, test_size=0.1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(test, y, test_size=0.1, random_state=42)\n",
    "X_train, y_train = smt.fit_resample(X_train, y_train)\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=25, batch_size=124, callbacks=[plot_losses, es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37389bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "for ele in predictions:\n",
    "    if ele[0] > 0.5:\n",
    "        ele[0] = 1\n",
    "    else:\n",
    "        ele[0] = 0\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fb2f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_array2 = np.hstack((dtm2, bow2, sent2vec2, fasttext2, doc2vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b222f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52d2e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_neg = 0\n",
    "count_pos = 0\n",
    "for ele in df['binary_labels']:\n",
    "    if ele > 0:\n",
    "        count_pos += 1\n",
    "    else:\n",
    "        count_neg +=1\n",
    "print(count_neg)\n",
    "print(count_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3663b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335fef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8247573",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(labeled_sentiment.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56932b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = result_test.join(labeled_sentiment[6], how='left', lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = result_test.apply(lambda row: TaggedDocument(words=row[4], tags=row[5]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c790980",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in test:\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7182b2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-1bb8afcd6693>:4: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  model = FastText.load_fasttext_format('crawl-300d-2M.vec')\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Supervised fastText models are not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1bb8afcd6693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatapath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_fasttext_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'crawl-300d-2M.vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 )\n\u001b[0;32m-> 1519\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36mload_fasttext_format\u001b[0;34m(cls, model_file, encoding)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \"\"\"\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_facebook_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     @utils.deprecated(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36mload_facebook_model\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     \"\"\"\n\u001b[0;32m--> 717\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_load_fasttext_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36m_load_fasttext_format\u001b[0;34m(model_file, encoding, full_model)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \"\"\"\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fasttext_bin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     model = FastText(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/_fasttext_bin.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fin, encoding, full_model)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0mraw_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/_fasttext_bin.py\u001b[0m in \u001b[0;36m_load_vocab\u001b[0;34m(fin, new_format, encoding)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# Vocab stored by [Dictionary::save](https://github.com/facebookresearch/fastText/blob/master/src/dictionary.cc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnlabels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Supervised fastText models are not supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading %s words for fastText model from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Supervised fastText models are not supported"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "model = FastText.load_fasttext_format('crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4e4bd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastText in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (0.9.2)\r\n",
      "Requirement already satisfied: pybind11>=2.2 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from fastText) (2.7.1)\r\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from fastText) (52.0.0.post20210125)\r\n",
      "Requirement already satisfied: numpy in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from fastText) (1.19.5)\r\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastText'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-880a06835b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install fastText'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfastText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfastText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'crawl-300d-2M.vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastText'"
     ]
    }
   ],
   "source": [
    "!pip install fastText\n",
    "import fastText.util\n",
    "model = fastText.load('crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7489f3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fastText'...\n",
      "remote: Enumerating objects: 3854, done.\u001b[K\n",
      "remote: Total 3854 (delta 0), reused 0 (delta 0), pack-reused 3854\u001b[K\n",
      "Receiving objects: 100% (3854/3854), 8.22 MiB | 3.45 MiB/s, done.\n",
      "Resolving deltas: 100% (2417/2417), done.\n",
      "Requirement already satisfied: fastText in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (0.9.2)\n",
      "Requirement already satisfied: numpy in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from fastText) (1.19.5)\n",
      "Requirement already satisfied: pybind11>=2.2 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from fastText) (2.7.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from fastText) (52.0.0.post20210125)\n",
      "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
      " (100.00%) [==================================================>]================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ] ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]=================================================> ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "model = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebc843c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00509833,  0.02135662, -0.01184329,  0.05266943, -0.16864014,\n",
       "       -0.04841997,  0.05334626, -0.02049172,  0.00845174,  0.01429758,\n",
       "        0.06533916,  0.00362429, -0.08987163, -0.03336754, -0.18756333,\n",
       "        0.00772139,  0.01278595, -0.11340928, -0.06350299,  0.04507144,\n",
       "        0.08678526, -0.00409233, -0.10335849,  0.04887098,  0.0212962 ,\n",
       "       -0.01170824,  0.03704761, -0.00066435,  0.01197213,  0.09252562,\n",
       "       -0.02096017, -0.00589347, -0.00238095, -0.04378781,  0.07234428,\n",
       "       -0.0367375 , -0.01533426,  0.03775294,  0.04420847, -0.00628774,\n",
       "       -0.03281379, -0.02526125, -0.02368759, -0.08459011,  0.00215459,\n",
       "        0.01372246, -0.03623858,  0.0316424 ,  0.05908176, -0.12449559,\n",
       "       -0.01266178, -0.02548024,  0.00355392, -0.09542252, -0.0074124 ,\n",
       "       -0.02880424,  0.15027776,  0.0308898 , -0.04817026, -0.06828777,\n",
       "        0.03918895,  0.00364412, -0.10868607, -0.00242731, -0.01519961,\n",
       "       -0.04794849, -0.03293444,  0.10084325, -0.08015182, -0.18052949,\n",
       "        0.00334742, -0.06537405,  0.03807873, -0.02361698, -0.09355527,\n",
       "        0.10419156,  0.02210759,  0.07769962, -0.02061073, -0.00822443,\n",
       "        0.04215488,  0.0491778 ,  0.0469548 , -0.02177161, -0.02406868,\n",
       "        0.07771432,  0.00777287, -0.04977106, -0.05809179, -0.04123195,\n",
       "       -0.08740011, -0.01588233,  0.08370505,  0.14120445,  0.00907941,\n",
       "       -0.02007971, -0.03718072,  0.1298615 , -0.05279427, -0.02353549,\n",
       "       -0.06204232,  0.03151739,  0.0453134 ,  0.00752538,  0.04024702,\n",
       "        0.0610389 , -0.01243567,  0.00870261,  0.01711629,  0.00569353,\n",
       "        0.05969729,  0.09794761, -0.08569312,  0.01664822, -0.13958624,\n",
       "        0.08890878, -0.11531384, -0.07407642, -0.02298455,  0.03376094,\n",
       "        0.0248992 , -0.07044517, -0.04073255, -0.00566212, -0.06390872,\n",
       "        0.02871   ,  0.12529755, -0.05540295, -0.06391544, -0.01125944,\n",
       "       -0.03670572,  0.04459884, -0.00202454,  0.09078018,  0.01332802,\n",
       "       -0.18304622, -0.01876665, -0.02669292,  0.15047179,  0.05510272,\n",
       "       -0.0675757 , -0.02280755,  0.01363657,  0.06124565, -0.00444846,\n",
       "       -0.07070126, -0.13786887, -0.07316618, -0.08153784, -0.06120001,\n",
       "       -0.08106904,  0.06377053,  0.02996236, -0.0449697 ,  0.0585052 ,\n",
       "        0.0192818 ,  0.01678927,  0.01526126,  0.06198548, -0.00873695,\n",
       "        0.02507791, -0.15352392,  0.11269405, -0.11410719,  0.08436203,\n",
       "       -0.06992202, -0.07377723, -0.0856187 , -0.01824745, -0.08791059,\n",
       "        0.05049798, -0.04762868,  0.03634075, -0.02623121, -0.03906174,\n",
       "       -0.03799345,  0.0666768 ,  0.08004767, -0.17656699, -0.08995945,\n",
       "       -0.04074486,  0.00242944,  0.02616011, -0.12452193, -0.10509706,\n",
       "       -0.04456471,  0.01706069, -0.07027378, -0.02897863, -0.00940995,\n",
       "        0.02054264, -0.077223  ,  0.10053004, -0.06137724, -0.06864616,\n",
       "       -0.02661854, -0.05970972, -0.14645015, -0.0002069 ,  0.01859084,\n",
       "       -0.09474619,  0.10685508, -0.02822135, -0.01438917, -0.08398292,\n",
       "       -0.04966272, -0.0228992 ,  0.03036434,  0.04887646,  0.1621554 ,\n",
       "       -0.0800326 , -0.04096222, -0.07376368,  0.15577176,  0.07228631,\n",
       "        0.00387494,  0.03276121,  0.01767325, -0.07842043, -0.00343439,\n",
       "        0.05430425, -0.11727414, -0.10559519,  0.0078255 , -0.0870839 ,\n",
       "        0.07529971, -0.07926812, -0.01589645, -0.0262425 , -0.00389064,\n",
       "        0.00102304, -0.01467134, -0.03670932,  0.16213454,  0.00109185,\n",
       "       -0.02121366,  0.08253387,  0.14206423,  0.03714128,  0.11073132,\n",
       "       -0.06816251, -0.01629031, -0.02947365, -0.1090044 ,  0.16681519,\n",
       "       -0.04569814, -0.05794126, -0.08170422,  0.05420335,  0.00234725,\n",
       "        0.02054504, -0.01050942, -0.0238814 ,  0.11536971, -0.00965991,\n",
       "        0.04805467, -0.11332007,  0.08909339,  0.04270995,  0.00431399,\n",
       "        0.02187527, -0.00526111,  0.01614785,  0.08761496,  0.05231253,\n",
       "        0.01160091, -0.00878457, -0.01195659, -0.0049683 , -0.01463292,\n",
       "        0.0584704 , -0.13551521, -0.06099027, -0.04140973,  0.04461792,\n",
       "        0.0638269 , -0.04909787,  0.07522127,  0.00167937,  0.02258638,\n",
       "       -0.09571715, -0.10515631, -0.05283113, -0.10467654, -0.05511772,\n",
       "        0.01870064, -0.08109561,  0.07631323,  0.09363045, -0.01854144,\n",
       "        0.04567406, -0.08907477, -0.07167261,  0.07049166,  0.06861213,\n",
       "       -0.0223221 ,  0.01035208,  0.01941329,  0.0366926 , -0.03240998],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_word_vector('trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f84eec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.07123163e-02, -3.27552557e-02, -2.02024058e-02,  1.13675669e-02,\n",
       "       -8.55093822e-02,  4.96805273e-03,  3.72172296e-02,  1.63765196e-02,\n",
       "        1.18740899e-02,  5.44424057e-02,  2.23458968e-02,  2.89542265e-02,\n",
       "        1.74480435e-02,  1.01826182e-02, -3.55550200e-02,  3.31443511e-02,\n",
       "       -3.41617242e-02, -3.73048410e-02, -2.39844769e-02, -1.38647240e-02,\n",
       "       -2.71656830e-02, -1.29203722e-02,  4.68241191e-03,  1.98373720e-02,\n",
       "        1.03247548e-02, -2.05309410e-03, -1.66373812e-02, -3.85794626e-03,\n",
       "       -4.18190286e-03,  9.99124199e-02, -3.81077006e-02, -1.55281927e-03,\n",
       "       -3.84739460e-03, -3.64658572e-02,  3.78771638e-03, -1.95074584e-02,\n",
       "        1.15069384e-02,  4.75481153e-02,  3.15180421e-02, -1.17069483e-03,\n",
       "       -3.42417918e-02,  4.23769467e-04, -1.09507404e-02, -1.81155335e-02,\n",
       "       -2.13997103e-02, -1.31161660e-02,  2.37541106e-02, -1.30674662e-02,\n",
       "        6.45487979e-02, -2.83987038e-02,  8.27041827e-03, -1.22156600e-02,\n",
       "       -2.54437029e-02, -7.94899017e-02, -1.57958306e-02, -1.72181129e-02,\n",
       "        6.12976588e-03, -2.99035273e-02,  1.09607885e-02, -1.51505545e-02,\n",
       "        4.32466827e-02, -1.00639286e-02, -1.39500294e-02, -6.80661574e-03,\n",
       "       -1.98992454e-02, -1.44873485e-02, -1.48456506e-02, -1.81174576e-02,\n",
       "        1.52520463e-02, -1.81796923e-02,  5.03435731e-04, -3.76244895e-02,\n",
       "        3.16112265e-02, -1.89254992e-04, -2.41308995e-02, -4.46528196e-03,\n",
       "        1.40175382e-02, -2.56658569e-02, -5.30016720e-02, -1.63831599e-02,\n",
       "        2.04146653e-02, -1.99410841e-02, -1.10617476e-02, -1.20637342e-02,\n",
       "       -2.39295885e-02, -2.93986872e-03,  8.41299258e-03, -2.37963162e-02,\n",
       "        4.91613969e-02,  1.32878451e-03,  2.27806112e-03,  7.46686477e-03,\n",
       "        1.05095170e-02, -6.78171869e-04, -2.40367278e-02,  6.50874376e-02,\n",
       "       -7.28066266e-02,  2.92533860e-02, -8.13000649e-03,  1.61839724e-02,\n",
       "       -2.53173374e-02,  3.38749774e-02,  2.77481936e-02, -1.95261911e-02,\n",
       "        3.73498164e-03,  3.07374895e-02, -1.77028812e-02,  2.26612147e-02,\n",
       "        3.43877673e-02,  1.42343845e-02,  1.83405448e-02, -1.26474146e-02,\n",
       "       -1.62979029e-03,  5.18558957e-02,  1.50068980e-02,  1.15073714e-02,\n",
       "       -2.76704058e-02,  2.86584087e-02, -6.82218093e-03, -5.97495064e-02,\n",
       "       -4.23535705e-02,  8.94120079e-04,  2.44861823e-02,  1.24825975e-02,\n",
       "       -1.70023628e-02, -3.79901566e-02, -8.08330253e-04, -8.43393151e-03,\n",
       "        3.05619277e-03,  4.72442470e-02, -3.72987837e-02,  9.49150603e-03,\n",
       "        4.72978726e-02, -9.77547746e-03, -4.24201936e-02, -3.37113328e-02,\n",
       "       -4.61746566e-02, -9.05860215e-05,  5.14290947e-03,  4.34884429e-02,\n",
       "       -4.59768213e-02, -2.10300777e-02,  9.66920517e-04, -4.81123943e-03,\n",
       "       -3.12938029e-03,  1.44627392e-02, -2.08091855e-01, -1.04876952e-02,\n",
       "       -3.85109521e-03, -4.62890789e-02, -6.20951429e-02, -2.24383734e-03,\n",
       "        6.04026020e-02,  6.79070037e-03,  2.81610154e-02, -5.35171386e-03,\n",
       "        7.44978935e-02, -2.11790185e-02,  2.01689266e-02,  2.55164355e-02,\n",
       "        2.82459259e-02, -1.49924597e-02,  1.50811998e-02,  8.61994922e-03,\n",
       "        2.56837867e-02,  6.07671775e-03, -4.48907074e-03, -7.40686618e-03,\n",
       "        2.97588436e-03, -8.40092637e-03, -2.64667124e-02,  1.14724524e-02,\n",
       "        4.00878377e-02, -2.75033675e-02,  6.46290788e-03,  3.73163000e-02,\n",
       "        2.80901603e-02,  9.21734795e-03, -4.72595394e-02, -1.06728431e-02,\n",
       "        3.77104878e-02,  7.12777823e-02, -3.52549134e-03, -4.91210539e-03,\n",
       "       -4.41520102e-02, -2.10918300e-03, -5.77418432e-02, -2.61527915e-02,\n",
       "        3.18934843e-02,  6.42144214e-03, -1.51689071e-02,  6.62940927e-03,\n",
       "       -3.86874489e-02, -2.65482925e-02,  1.01646846e-02,  7.93648418e-04,\n",
       "       -1.66004635e-02, -1.83555111e-02, -2.58799130e-03, -9.78869619e-04,\n",
       "        2.69091618e-03,  7.59359896e-02,  2.42431201e-02,  3.59867141e-02,\n",
       "        6.48795534e-03, -3.49433124e-02,  2.47394629e-02, -1.44188255e-02,\n",
       "        7.49799237e-02, -8.45166389e-03,  2.05467604e-02,  1.50314309e-02,\n",
       "       -5.46394847e-02,  1.74435973e-02,  1.05594592e-02,  1.81368999e-02,\n",
       "        4.72283959e-02, -1.67825632e-02, -2.96347365e-02,  5.68387564e-03,\n",
       "        2.03913841e-02,  1.78756360e-02, -3.32750008e-02, -1.52127985e-02,\n",
       "        2.92343646e-03, -3.04074436e-02, -1.82212945e-02, -4.66183946e-03,\n",
       "        3.16382237e-02, -8.79255822e-05,  5.26596047e-03,  8.73410143e-03,\n",
       "       -1.07970182e-02, -2.93111801e-02,  4.03748546e-03, -5.42217260e-03,\n",
       "        5.55678457e-02,  3.23204622e-02, -4.31343634e-03,  2.99420264e-02,\n",
       "       -1.14524076e-02,  7.32494667e-02,  1.84821375e-02, -3.14977542e-02,\n",
       "        2.68550843e-01, -4.31496873e-02,  2.47234236e-02,  3.88233289e-02,\n",
       "        2.59653572e-03, -3.78774665e-02,  4.10400704e-03,  3.58091015e-03,\n",
       "        3.13073844e-02,  2.58828979e-03, -1.41402343e-02, -3.01717408e-03,\n",
       "       -3.06344479e-02, -1.25881154e-02, -3.05907894e-02,  2.85858996e-02,\n",
       "        5.19482885e-03,  3.54152583e-02, -2.94784959e-02, -2.25524679e-02,\n",
       "       -1.87483728e-02, -1.88353974e-02, -8.96324310e-03,  4.82834643e-03,\n",
       "        4.39435989e-02,  6.15696516e-03, -1.20438701e-02, -8.48136842e-03,\n",
       "        4.18026140e-03,  3.64468782e-03, -1.73072163e-02, -4.74955924e-02,\n",
       "       -3.58123668e-02, -6.95674941e-02,  6.56660832e-03, -5.09092361e-02,\n",
       "       -1.65369678e-02, -2.78792828e-02, -9.83178690e-02, -6.08823635e-02,\n",
       "       -2.28139367e-02,  9.64849442e-03,  2.55476404e-03, -7.98921939e-03,\n",
       "       -3.15566100e-02, -1.77272363e-03,  2.61060838e-02,  1.31715313e-02,\n",
       "       -3.42619121e-02, -1.13825211e-02,  2.85036825e-02, -8.97336192e-03,\n",
       "        9.06694401e-03,  3.38534713e-02,  1.16653834e-02,  6.39918353e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_sentence_vector('Trump is in office')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d692159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sent2vec\n",
      "  Downloading sent2vec-0.2.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.1.1-cp38-cp38-macosx_10_9_x86_64.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-1.9.0-cp38-none-macosx_10_9_x86_64.whl (127.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 127.9 MB 38 kB/s s eta 0:00:01   |▎                               | 1.2 MB 10.7 MB/s eta 0:00:12     |█                               | 4.1 MB 10.7 MB/s eta 0:00:12     |██                              | 8.3 MB 10.7 MB/s eta 0:00:12     |██▋                             | 10.3 MB 10.7 MB/s eta 0:00:11     |███████▎                        | 29.0 MB 9.8 MB/s eta 0:00:11     |██████████▎                     | 41.3 MB 4.8 MB/s eta 0:00:19     |███████████████▌                | 61.9 MB 12.4 MB/s eta 0:00:06     |████████████████                | 63.7 MB 20.8 MB/s eta 0:00:04█████████████▋             | 74.3 MB 20.8 MB/s eta 0:00:03  |███████████████████▉            | 79.2 MB 16.7 MB/s eta 0:00:03     |█████████████████████▌          | 86.0 MB 16.7 MB/s eta 0:00:03     |███████████████████████▏        | 92.4 MB 12.0 MB/s eta 0:00:03��███████▌        | 94.1 MB 12.0 MB/s eta 0:00:03     |████████████████████████▉       | 99.5 MB 12.0 MB/s eta 0:00:03 |██████████████████████████▋     | 106.4 MB 8.6 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting transformers\n",
      "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 14.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gensim in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from sent2vec) (4.0.1)\n",
      "Requirement already satisfied: numpy in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from sent2vec) (1.19.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from gensim->sent2vec) (5.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from gensim->sent2vec) (1.6.2)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.7\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.1-cp38-cp38-macosx_10_9_x86_64.whl (450 kB)\n",
      "\u001b[K     |████████████████████████████████| 450 kB 15.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp38-cp38-macosx_10_9_x86_64.whl (18 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp38-cp38-macosx_10_9_x86_64.whl (105 kB)\n",
      "\u001b[K     |████████████████████████████████| 105 kB 20.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.4\n",
      "  Downloading catalogue-2.0.4-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from spacy->sent2vec) (2.11.3)\n",
      "Requirement already satisfied: setuptools in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from spacy->sent2vec) (52.0.0.post20210125)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp38-cp38-macosx_10_9_x86_64.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 18.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from spacy->sent2vec) (20.9)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.0-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting thinc<8.1.0,>=8.0.8\n",
      "  Downloading thinc-8.0.8-cp38-cp38-macosx_10_9_x86_64.whl (598 kB)\n",
      "\u001b[K     |████████████████████████████████| 598 kB 16.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp38-cp38-macosx_10_9_x86_64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 9.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp38-cp38-macosx_10_9_x86_64.whl (31 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from spacy->sent2vec) (4.59.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from spacy->sent2vec) (2.25.1)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy->sent2vec) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy->sent2vec) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->sent2vec) (2020.12.5)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy->sent2vec) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy->sent2vec) (1.1.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from transformers->sent2vec) (2021.4.4)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-macosx_10_11_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 24.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 24.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from transformers->sent2vec) (5.4.1)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: filelock in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from transformers->sent2vec) (3.0.12)\n",
      "Requirement already satisfied: joblib in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers->sent2vec) (1.0.1)\n",
      "Requirement already satisfied: six in /Users/steve/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers->sent2vec) (1.15.0)\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, pydantic, preshed, blis, tokenizers, thinc, spacy-legacy, sacremoses, pathy, huggingface-hub, transformers, torch, spacy, sent2vec\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.4 cymem-2.0.5 huggingface-hub-0.0.12 murmurhash-1.0.5 pathy-0.6.0 preshed-3.0.5 pydantic-1.8.2 sacremoses-0.0.45 sent2vec-0.2.0 spacy-3.1.1 spacy-legacy-3.0.8 srsly-2.4.1 thinc-8.0.8 tokenizers-0.10.3 torch-1.9.0 transformers-4.9.1 typer-0.3.2 wasabi-0.8.2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sent2vec' has no attribute 'Sent2vecModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-94de9fa87a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install sent2vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msent2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSent2vecModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"once upon a time .\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sent2vec' has no attribute 'Sent2vecModel'"
     ]
    }
   ],
   "source": [
    "!pip install sent2vec\n",
    "import sent2vec\n",
    "model = sent2vec.Sent2vecModel()\n",
    "model.load_model('model.bin')\n",
    "emb = model.embed_sentence(\"once upon a time .\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1dddb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
